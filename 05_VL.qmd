---
title: "Business Intelligence & Data Science"
subtitle: "Vorlesung 5"
format:
  revealjs:
    incremental: false  
---
  
```{r}

library(kableExtra)
library(readr)
library(magrittr)
library(dplyr)
```




## Der Plan für heute...
### Vorlesung 

::: {style="font-size: 0.9em"}
* Quiz und Recap
* Visualisierung von Anteilen: Kreisdiagramme, Treemaps und Sankey Plots
* Informationsgenerierung
  * Welche Formen von Berichten gibt es?
  * Was ist OLAP?
  * Wo genau unterscheiden sich Self-Sevice BI und traditionelle BI?
* Modellgestützte Analysen
  * Wie läuft ein Data Science Projekt ab?
  * Begriffliche Grundlagen Data Science
:::


## Kurzer Überblick: Wo geht's weiter?
### Informationsgenerierung
![BIA Gesamtansatz. Eigene Darstellung in Anlehnung an @baars_business_2021.](img/bia_ordnungsrahmen.drawio.png){width="700" height="500"}

# Informationsgenerierung

## Berichtsorientierte Analyse
### Reporting

* Ein Bericht oder Report gibt einen Überblick über betriebswirtschaftliche Sachverhalte eines abgegrenzten Verantwortungsbereichs
* In der Regel durch Visualisierung von Zusammenhängen in grafischer Form
* Betriebliches Berichtswesen wird in interne und externe Berichterstattung unterteilt:
  * Internes Berichtswesen: Informationen für das Management, bspw. internes Rechnungswesen
  * Externes Berichtswesen: Informationen für externe Stakeholder, bspw. Jahresbericht

## Berichtsorientierte Analyse
### Reporting


* Aktive Berichtskomponenten:
  * Werden nach einmaliger Spezifikation der Inhalte und Formate regelmäßig erstellt und aktiv versandt, entweder:
    * Periodisch: In festen Zeitabständen (jede Woche, jedes Quartal)
    * Aperiodisch: Bei Überschreitung bestimmter Grenzwerte (z.B. Umsatzgrenze)
* Passive Berichtskomponenten:
  * Werden nur auf konkrete Anforderungen der Anwendenden erstellt
  * Individuelle und bedarfsspezifische Berichte
  * Auch Ad-hoc Berichtskomponente genannt, oft mit OLAP und Self-Service Tools umgesetzt


## Berichtsorientierte Analyse
### OLAP

* Online Analyitical Processing (OLAP) ermöglicht die Bereitstellung anwendungsfreundlicher und gleichermaßen flexibler Abfragen in multidimensionalen Datenräumen
* Form des Ad-hoc Reportings
* OLAP-Komponenten sind weitgehend mit Pivot Tabellen in Excel oder Google Sheets vergleichbar
* Aber: Erweitert um ein zentrales Datenmodell (meist Data Mart basiert) und Rollenverwaltung

## OLAP
### Datenmodell als Würfel

:::: {.columns}
::: {.column width="50%"}
::: {style="font-size: 0.9em"}
* Bestehen konzeptionell aus Fakten, Dimensionen und Hierarchien
* Da oft mehrere Dimensionen vorliegen, spricht man von Cubes
* Theoretisch ist der Zahl an Dimensionen keine Grenzen gesetzt, in der Praxis aber im einstelligen Bereich begrenzt
* Bei mehr als 3 Dimensionen spricht man oft von Hypercube
* Bei der Erstellung von Reports aus OLAP Cubes spricht man oft von OLAP Operationen 

:::
:::

::: {.column width="50%"}

![Cube mit den Dimensionen Zeit, Produkt und Kunde. Quelle: [Wikipedia](https://de.wikipedia.org/wiki/OLAP-W%C3%BCrfel)](img/plot-cube.PNG){width=100%}

:::
::::

## OLAP

### Slicing

* Slicing ist die Entnahme einer einzigen Dimension, indem eine ausgewählte Dimension auf einen Wert reduziert wird
* Im Beispiel wird der dreidimensionale Raum mit den Jahreswerten 2004--2006 auf das Jahr 2004 reduziert und so eine einzelne Scheibe aus dem Cube entnommen

![OLAP Slicing. Quelle: [Wikipedia](https://de.wikipedia.org/wiki/OLAP-W%C3%BCrfel)](img/OLAP_slicing.png){width=60%}


## OLAP

### Dicing

* Dicing ist die Einschränkung mehrerer Dimensionen auf ausgewählte Werte, sodass ein neuer, kleinerer Würfel entsteht
* Im Beispiel wird die Anzahl der Produktkategorien von fünf auf drei reduziert

![OLAP Dicing Quelle: [Wikipedia](https://de.wikipedia.org/wiki/OLAP-W%C3%BCrfel)](img/OLAP_dicing.png){width=60%}


## OLAP
### Pivotierung

::: {style="font-size: 0.78em"}

* Auswertung erfolgt meist auf zweidimensionalen Ausschnitten aus dem Cube, beispielsweise Produktkategorie pro Jahr
* Grafisch entspricht eine solche Ansicht einer Seite des Würfels
* Durch Pivotierung wird der Würfel um eine Achse gedreht
* Im Beispiel: Geografie pro Jahr statt Produktkategorie über Geografie

:::

![OLAP Pivotierung/Rotation Quelle: [Wikipedia](https://de.wikipedia.org/wiki/OLAP-W%C3%BCrfel)](img/OLAP_pivoting.png){width=55%}


## OLAP
### Roll-Up, Drill-Down & Drill-Through 

* Beim Roll-Up werden die Werte einer Hierarchieebene auf die Werte einer übergeordneten Hierarchieebene aggregiert
* Beim Drill-Down wiederum wird ein aggregierter Wert in die einzelnen Bestandteile aufgeschlüsselt, bspw. die Betrachtung von einzelnen Monaten im Jahr 2004
* In einigen Fällen wird beim Drilling die physikalische Datenquelle gewechselt, da beispielsweise nur eine begrenzte Granularitätsstufe im aktuellen Cube verfügbar ist
* Das geschieht im Normalfall ohne Wissen der Anwendenden, die die Abfrage stellen

## OLAP
### Physikalische Umsetzung und Anbindungsschnittstellen

* Die Datenhaltung erfolgt in OLAP Komponenten weitgehend unabhängig von der Anwendungsansicht meist in Client-Server-Architekturen und die Datenhaltung erfolgt serverseitig
* OLAP-Anwendungen erfordern zudem eine Programmoberfläche und oft erfolgt die Einbindung in  Tabellenkalkulationsprogramm wie Excel
* Ein bekanntes Beispiel ist [SAP Analysis](https://help.sap.com/docs/SAP_BUSINESSOBJECTS_ANALYSIS_OFFICE/ca9c58444d64420d99d6c136a3207632/ebf198667aa54740b9049d9da804a901.html?version=2.8.19.0) für Excel
* Andere gängige Praxis sind webbasierte Schnittstellen wie [Cubeware Cockpit](https://www.cubeware.com/content/Produkte/C8_Cockpit/C8-Cockpit-Viewer_DE.pdf) 
  
  
## Self-Service BI
### Das Versprechen von Self-Service BI

* Self Service BI setzt beim Versprechen an, die Anwendenden in die Lage zu versetzen eigenständig und flexibel den Datenbestand nach neuen Verknüpfungen zu untersuchen
* Das kann zudem weitgehend unabhängig von der Unternehmens-IT betrieben und bedient werden
* Traditionelle BI-Lösungen sind oft als zu starr angesehen, wenn es darum geht, neue Reporting Anforderungen rasch umzusetzen und damit innovative Analysen zu testen

## Self-Service BI vs. Traditionelle BI
### Blick auf die alte Welt


![Traditionelle BI, Quelle: [Fidelity](https://datafidelity.io/business-intelligence-solutions/)](img/Traditional-Approach-1.png){width=80%}


## Self-Service BI vs. Traditionelle BI
### Versprechen der neuen Welt am Beispiel von Looker


![Traditionelle BI, Quelle: [Fidelity](https://datafidelity.io/business-intelligence-solutions/)](img/modern-approach-scaled.jpg){width=80%}

# Modellgestützte Analysen




## Der Data Science Prozess 
### Ablauf von Data Science Use Cases

:::: {.columns}
::: {.column width="55%"}
::: {style="font-size: 0.95em"}
* Data Science Projekte sind in der Praxis aufwendig und erfordern stets die Zusammenarbeit zwischen Fachabteilungen und Data Science Team
* Deshalb wurden feste Prozesse etabliert, bspw. der Cross Reference Industry Standard Process for Data Mining (CRISP-DM)
* CRISP-DM besteht aus 6 Phasen, die iterativ durchlaufen werden
* Rückkopplungen zwischen den Phasen sind dabei oft notwendig
:::
:::

::: {.column width="45%"}


![CRISP-DM Prozess. Eigene Darstellung in Anlehnung an @donofrio_rundgang_2021.](img/CRISP_DM.drawio.png){width=70%}

:::
::::


## CRISP-DM
### Geschäftsmodell


1. Verständnis des Geschäftsmodells
    * Verständnis des Geschäftsmodells und der Unternehmensziele
    * Berücksichtigung von Chancen, Risiken und zeitlichen Aspekten
    * Definition des erwartbaren Nutzens und messbarer Erfolgskriterien

## CRISP-DM
### Anwendungs-/Datendomäne und Datenvorbereitung

2. Verständnis der Anwendungs- und Datendomäne
    * Analyse der Unternehmensprozesse und Datenquellen
    * Zusammenführung, Beschreibung und Exploration der Zieldaten
    * Eruierung der Datenqualität
3. Datenvorbereitung
    * Zusammenführung und Beschreibung polystrukturierter Daten
    * Berechnung von Kennzahlen und Durchführung von Datentransformationen

## CRISP-DM
### Modellierung, Evaluation und Bereitstellung

4. Modellierung
    * Modellauswahl und -erstellung
    * Iterativer Prozess zur Weiterentwicklung von Modellen
    * Möglicher Einsatz vortrainierter Modelle für die Verfeinerung
5. Evaluation
    * Bewertung der erstellten Modelle anhand definierter Erfolgskriterien
6. Einsatz
    * Umsetzung der Ergebnisse in die Praxis und Integration in die Unternehmensprozesse


## Begriffliche Grundlagen
### Eine Gleichung, viele Anwendungen

::: {style="font-size: 0.89em"}
* Die Generierung von modellbasierten Erkenntnissen aus Daten erfordert eine Definition des Lernproblems, oft mit einer simplen Gleichung:

$$
y = f(X) + \epsilon
$$ 

*  $y$ ist ein $N \times 1$ Vektor mit einer Ergebnisvariablen
* $X$ ist eine $N \times P$ Matrix mit Prädiktoren $X_1, X_2,..., X_P$
* $N$ entspricht der Anzahl von Beobachtungen im vorliegenden Datensatz, $P$ ist die Anzahl der Prädiktoren
* Anstelle von Prädiktoren werden oft die Begriffe erklärende oder unabhängige Variablen oder Features verwendet
* $f$ beschreibt alle systematischen Zusammenhänge zwischen $X$ und $y$, während der Fehlerterm $\epsilon$ alle Variation in $X$ aufnimmt, die nicht von $f$ erklärbar sind

:::


## Begriffliche Grundlagen
### Vorhersage vs. Inferenz

* Angenommen, wir haben eine Funktion $f$ sowie einen Algorithmus gefunden, um $f$ an unsere Variablen $y$ und $X$ anzupassen
* Die Modellschätzung wird auch als Modelltraining oder Modellanpassung bezeichnet und unser trainiertes Modell hat die Form:

$$
\hat{y} = \hat{f}(X)
$$ 

* Das trainierte Modell hat keien Fehlerterm $\epsilon$, da dieser die Variation in den Daten darstellt, die vom Modell nicht erfasst wird und unvorhersehbar ist
* Geschätzte Größen werden mit einem Zirkumflex-Symbol (^) gekennzeichnet


## Begriffliche Grundlagen
### Vorhersage vs. Inferenz
* Das Modell kann nun für zwei Zwecke verwendet werden:
  * Vorhersage: Schätzung von $y$ für neue, nicht im Modell enthaltene Daten
  * Inferenz: Verständnis der Beziehungen und Muster in den Daten, die das Modell gelernt hat
* Inferenz erfordert ein genaues Verständnis der Zusammenhänge
* Bei Vorhersage kümmern wir uns nicht um seine genaue Struktur oder Parameter des Modells, sondern ausschließlich um die generierten Vorhersagen.



## Begriffliche Grundlagen
### Klassifikation vs. Regression



* Die Art der Variablen $y$ bestimmt die Art des Modells, das wir verwenden
* Variablen sind entweder *kategorisch* oder *numerisch*, oft auch als *qualitativ* und *quantitativ* bezeichnet
* Wenn die abhängige Variable numerisch ist, ist es möglich, den exakten Wert der Variable vorherzusagen, dann liegt ein Regressionsproblem vor
* Wenn die abhängige Variable kategorisch ist, lässt sich lediglich die erwartete Klasse vorhersagen, basierend auf einer Wahrscheinlichkeit, dann liegt ein Klassifikationsproblem vor
* Wichtig: Hierbei ist nur die Art der abhängigen Variable entscheidend

## Begriffliche Grundlagen
### Kategoriale Daten

* Kategoriale Daten umfassen verschiedene Kategorien oder Labels
* Bei kategorialen Daten wird wiederum zwischen nominalen und ordinalen Variablen unterschieden
* Nominaldaten repräsentieren Kategorien ohne eine inhärente Rangfolge:
  * Farben (rot, blau, grün),
  * Familienstand (ledig, verheiratet, geschieden, ...),
* Ordinaldaten weisen eine spezifische Reihenfolge oder Hierarchie auf, aber keine gleichmäßigen Abstände zwischen den Kategorien:
  * Schärfe von Essen (mild, pikant, scharf),
  * Expertise mit Programmiersprachen (keine, wenig, fortgeschritten, professionell)


## Begriffliche Grundlagen
### Numerische Daten

:::: {.columns}
::: {.column width="50%"}
* *Numerische* Daten reräsentieren Mengen, Messungen, und allgemein numerische Werte
* Lassen sich mit mathematichen Operationen verarbeiten und manipulieren
* Numerische Daten können entweder *diskret* oder *kontinuierlich* sein, Beispiele:
  * Alter,
  * Temperatur,
  * Finanzwerte ($ oder €)
:::
::: {.column width="50%"}
![Stetig vs. Diskret, Quelle: [Allison Horst](https://twitter.com/allison_horst)](img/discrete_vs_continuous.png)
:::
::::

## Begriffliche Grundlagen
### Überwachtes vs. Unüberwachtes Lernen

* Überwachte Lernprobleme weisen eine mess- oder beobachtbare abhängige Variable  $y_i, i = 1,2,...N$ für jede Beobachtung $i$ auf sowie eine oder mehrere Prädiktoren
* Unüberwachte Lernprobleme hingegen haben keine abhängige Variable, sondern versuchen, Muster in den Daten zu finden
* Die Mehrheit der Data Science Projekte sind überwacht, da sie auf der Vorhersage von $y$ basieren
* Auch wir konzentrieren uns bei der Klassifikation auf 


## Slide Title {visibility="hidden"}
@james_introduction_202

## Quellen