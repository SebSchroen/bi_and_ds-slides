---
title: "Business Intelligence & Data Science"
subtitle: "Vorlesung 3"
format:
  revealjs:
    incremental: true  
---
  
```{r}

library(kableExtra)
library(tidyverse)
library(patchwork)
library(ggthemes)
market_share <- read_csv("data/market_research.csv") %>% 
  pivot_longer(cols = -c(Year), names_to = "Anbieter", values_to = "User")

```




## Der Plan für heute...
### Vorlesung 3
:::{.incremental}
* Quiz
* Self-Service BI Terminologie
* Recap zur Aufgabe von letzter Woche und gemeinsamer Walk-Through
* Visualisierungstyp Balkendiagramm
* Datentransformation:
  * Was heißt ETL?
  * Welche Transformationschritte durchlaufen operative Daten bis zur Speicherung im DWH?
* Gemeinsame Transformation eines Datensatzes mit User-Events

:::

# Recap & Self-Service BI


## Self-Service BI
### Terminologie
::: {style="font-size: 0.95em"}
* Dashboard:
  * Eine Sammlung von Visualisierungen, die in einem gemeinsamen Kontext dargestellt werden
  * Ein Dashboard kann mehrere Visualisierungen enthalten, die auf unterschiedlichen Datasets basieren
  * Die Visualisierungen können über globale Filter gefiltert werden
* Chart:
  * Eigenständige Visualisierung eines Datasets, die eigenständig oder in einem Dashboard dargestellt werden kann
  * Es gibt eine Vielzahl von Chart-Typen, die in Superset dargestellt werden können
  * [Preset.io](https://docs.preset.io/docs/chart-walkthroughs) gibt eine Übersicht über die gängigsten Chart-Typen
:::  

## Self-Service BI
### Terminologie
::: {style="font-size: 0.90em"}
* Dimensions:
  * Dimensionen sind die Kategorien, nach denen Daten gruppiert wird
  * Idealerweise kategoriale Variablen, die nicht aggregiert werden
  * Wenn die Daten eine Zeitdimension enthalten (erkennbar am Uhren-Symbol) ist eine spezielle Time Dimension verfügbar
  * Bei korrekter Pflege der Zeitvariable lässt sich direkt auf Tages-, Wochen-, Monats- und Jahreswerte aggregieren mittels Time Grain
* Metrics
  * Quantitative Variablen, die sich mit Funktionen aggregieren lassen
  * Beispielfunktionen sind Summen, Durchschnitte, Min und Max oder Counts
  * Besonderheit: Viele BI-Tools erstellen per Default eine Count-Metrik, die Datenpunkte pro Dimension zählt

:::

## Self-Service BI
### Terminologie
::: {style="font-size: 0.90em"}
* Aggregationsfunktionen
  * Self-Service BI Tools werden meist mit Daten von höchster Granularität verknüpft, um die Flexibilität der Analyse zu erhöhen und Aggregationen seitens der Nutzenden zu ermöglichen
  * Aggregationsfunktionen werden auf Metriken angewendet, um die Daten zu verdichten
  * Einfache Beispiele sind Summen, Durchschnitte, Min und Max
  * Besonderheit Count und Count Distinct:
    * Count zählt die Anzahl der Datenpunkte,
    * Count Distinct zählt die Anzahl der einzigartigen Werte über die Dimension(en)
  * Semantisches Wissen und Fragestellung  sind für die Wahl der Aggregation entscheidend

:::

::: {.notes}
Beispieltabelle anschreiben:
Kunden A und B, Umsatz 100 und 50, Zufriedenheit (1-100%) 80  und 20
:::

## Self-Service BI
### Besonderheiten Superset
::: {style="font-size: 0.95em"}
* Database:
  * Backend-Datenbank, in der die Rohdaten liegen, das Pendant zu einem Data Warehouse
  * In unserem Fall Google BigQuery, aber auch andere Datenbanken wie MySQL, PostgreSQL oder SQLite sind möglich
  * Auch der Upload von Excel und CSV Dateien ist möglich
* Dataset:
  * Einzelne Tabellen in der Datenbank, die als Grundlage für Analysen und Visualisierungen dienen
  * Basieren auf Rohdaten, die für die Visualisierung verarbeitet werden
  * Physische Datasets "leben" auf der Backend-Datenbank, virtuelle Datasets sind direkt in Superset generiert und gespeichert
:::

## Business Case
### Recap zu den Fragen

:::: {.columns}
::: {.column width="35%"}
::: {style="font-size: 0.75em"}
* Fragen zu Tofispy
  1. Wächst Tofispy schneller oder langsamer als der Gesamtmarkt?
  2. Wie hoch ist der Marktanteil am Ende von 2024 voraussichtlich?
  3. Welcher Konkurrent wächst am stärksten?
  4. Sind die Daten dispositiv oder operativ?
  5. Welcher Reifegrad von Analytics liegt vor?
:::
:::

::: {.column width="65%"}


::: {style="font-size: 0.75em"}

* Tofispy verliert Marktanteile, wächst also langsamer als der Markt
* Der Marktanteil liegt Ende 2024 bei 34%
* YoutubeMusic wächst am stärksten
* Der Datensatz ist dispositiv und der Reifegrad  deskriptiv
:::


![](img/balkendiagramm.jpg){width="600" height="300"}
:::


::::

## Visualisierung
### Balkendiagramm
:::: {.columns}
::: {.column width="35%"}
::: {style="font-size: 0.75em"}
* Einfache Balkendiagramme eignen sich besonders gut zur Visualisierung absoluter Häufigkeiten
* Idealerweise ist die Anzahl der Dimensionen entlang der X-Achse dabei begrenzt
* Bei langen Dimensionsnamen ein horizontales Balkendiagramm verwenden, statt die Label auf der X-Achse zu drehen
* Zeitachse immer aufsteigend sortieren 
:::
:::



::: {.column width="65%"}


::: {.fragment .fade-in}

```{r, echo = FALSE, fig.width= 6, fig.height= 5.5}

vertical <- market_share %>% 
  group_by(Year) %>% 
  summarise(User = sum(User)) %>%
ggplot(data = ., aes(x = Year, y = User)) +
  geom_col(position = "dodge") +
  labs(title = "Vertikales Balkendiagramm",
       subtitle = "User in Mio insgesamt",
       x = "Jahr",
       y = "User in Mio.") +
  theme_minimal()

horizontal <- market_share %>% 
  group_by(Year) %>% 
  summarise(User = sum(User)) %>% 
  mutate(Year = year(Year)) %>% 
ggplot(data = ., aes(x = reorder(Year, -User), y = User)) +
  geom_col(position = "dodge") +
  labs(title = "Horizontales Balkendiagramm",
       subtitle = "User in Mio insgesamt",
       x = "Jahr",
       y = "User in Mio.") +
  theme_minimal() + 
  coord_flip()


vertical/horizontal


```


:::

:::
::::



## Visualisierung
### Gruppiertes Balkendiagramm
:::: {.columns}
::: {.column width="35%"}
::: {style="font-size: 0.75em"}
* Eignen sich für die Darstellung absoluter Häufigkeiten über mehrere Dimensionen
* Bei zu großen Unterschieden zwischen Gruppen schwer lesbar
* Auch hier: Bei langen Dimensionsnamen ein horizontales Balkendiagramm verwenden, statt die Label auf der X-Achse zu drehen und* Zeitachse immer aufsteigend sortieren 
:::
:::
::: {.column width="65%"}

::: {.fragment .fade-in}

```{r, echo = FALSE, fig.width= 6, fig.height= 5.5}

ggplot(data = market_share, aes(x = Year, y = User, fill = Anbieter)) +
  geom_col(position = "dodge") +
  labs(title = "Gruppiertes Balkendiagramm",
       subtitle = "User in Mio pro Anbieter",
       x = "Jahr",
       y = "User in Mio.",
       fill = "Anbieter") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_fill_tableau(palette = "Color Blind")

```

:::


:::
::::


## Visualisierung
### Gestapeltes Balkendiagramm
:::: {.columns}
::: {.column width="35%"}
::: {style="font-size: 0.75em"}
* Statt Darstellung nebeneinander, werden Balken gestapelt
* Sinnvoll, wenn die Summe der Beträge, eine sinnvolle Botschaft vermittelt
* Aber: Hierbei geht der Eindruck der Anteile der Dimensionen oft verloren, daher nicht ratsam, wenn die Anteile eigentlich von Interesse sind

:::
:::
::: {.column width="65%"}

::: {.fragment .fade-in}

```{r, echo = FALSE, fig.width= 6, fig.height= 5.5}

ggplot(data = market_share, aes(x = Year, y = User, fill = Anbieter)) +
  geom_col(position = "stack") +
  labs(title = "Gruppiertes Balkendiagramm",
       subtitle = "User in Mio pro Anbieter",
       x = "Jahr",
       y = "User in Mio.",
       fill = "Anbieter") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_fill_tableau(palette = "Color Blind")

```


:::

:::
::::



## Visualisierung
### Relatives gestapeltes Balkendiagramm
:::: {.columns}
::: {.column width="35%"}
::: {style="font-size: 0.75em"}
* Wenn die Anteile der Dimensionen wichtiger sind als die Summe bzw. die Summe keine sinnvolle Interpretation zulässt
* Hinweise des einfachen Balkendiagramms gelten weiterhin, ggf. horizontal und Jahreszahlen aufsteigend sortieren

:::
:::
::: {.column width="65%"}

::: {.fragment .fade-in}

```{r, echo = FALSE, fig.width= 6, fig.height= 5.5}

ggplot(data = market_share, aes(x = Year, y = User, fill = Anbieter)) +
  geom_col(position = "fill") +
  labs(title = "Gruppiertes Balkendiagramm",
       subtitle = "User in Mio pro Anbieter",
       x = "Jahr",
       y = "User in Mio.",
       fill = "Anbieter") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_fill_tableau(palette = "Color Blind")

```


:::

:::
::::

## Kurzer Überblick: Wo geht's weiter?
### Der ETL Prozess
![BIA Gesamtansatz. Eigene Darstellung in Anlehnung an @baars_business_2021.](img/bia_ordnungsrahmen.drawio.png){width="700" height="500"}


## ETL Prozess
### Was ist ETL?

::: {style="font-size: 0.90em"}
* ETL steht für Extract, Transform, Load oder auch Extraktion, Transformation, Laden
* **Extraktion** beschreibt die Übertragung der Daten aus den operativen Quellsystemen in einen Arbeitsbereich, oft Staging Area genannt
* Hier erfolgt die **Transformation**, die wiederum aus vier Teilschritten besteht:
  * Filterung
  * Harmonisierung
  * Aggregation
  * Anreicherung
* Anschließend werden die bereinigten und aufbereiteten Daten in die Zieldatenbank ge**laden**  
:::

## ETL Prozess
### Teilschritte der Transformation

```{r, etl, echo = FALSE}
#| fig.cap: Teilprozesse im ETL-Prozess. Eigene Darstellung in Anlehnung an @baars_business_2021


library(magrittr)

plot_marts_aligned <-DiagrammeR::grViz("digraph {

graph [layout = dot, rankdir = LR, newrank = true,  fontsize = 42]


node [shape = cylinder, style = filled, fillcolor = Linen, fontsize = 42]


sap [label = 'SAP', shape = cylinder, fillcolor = Beige, width = 1]
mes [label = 'MES', shape = cylinder, fillcolor = Beige, width = 1]
pdm [label = 'PDM', shape = cylinder, fillcolor = Beige, width = 1]


subgraph cluster_EBD {
label = 'Filterung'
labelloc = 'b'
extract1 [label =  'Extrakte', fillcolor = grey95, width = 1]
fextract1 [label =  'Bereinigte Extrakte',fillcolor = grey95, width = 1]
extract2 [label =  'Extrakte',fillcolor = grey95, width = 1]
fextract2 [label =  'Bereinigte Extrakte',fillcolor = grey95, width = 1]
extract3 [label =  'Extrakte',fillcolor = grey95, width = 1]
fextract3 [label =  'Bereinigte Extrakte',fillcolor = grey95, width = 1]

}

subgraph cluster_Harm {
label = 'Harmonisierung'
labelloc = 'b'
rankdir = TB
syntactic [label =  'Syntaktische Harmonisierung',fillcolor = grey96, width =1]
semantic [label =  'Semantische Harmonisierung',fillcolor = grey96, width = 1]


}



subgraph cluster_Agg {
label = 'Aggregation'
labelloc = 'b'
aggregation [label =  'Verdichtung und Hierarchisierung',fillcolor = grey97, width =1]
}

subgraph cluster_Anr {
label = 'Anreicherung'
labelloc = 'b'
anreicherung [label =  'Kennzahlberechnung',fillcolor = grey98, width =1]
}
# edge definitions with the node IDs
{sap} -> {extract1}
extract1 -> fextract1
{mes}-> {extract2}
{pdm} -> {extract3}
extract2 -> fextract2
extract3 -> fextract3
{fextract1 fextract2 fextract3} -> syntactic -> semantic -> aggregation -> anreicherung
}", height = 400, width = 1000)

plot_marts_aligned

```

## Filterung
### Extraktion und erste Bereinigung

* Filterung umfasst die Extraktion aus operativen Daten und die Bereinigung **syntaktischer** und **semantischer** Defekte in den Rohdaten
* Die Extraktion erfolgt vielfältig, z.B. über Flat File Transporte oder API Schnittstellen
* Aus Performance-Erwägungen wird die Extraktion mittels geplanter Batch-Jobs oft außerhalb der Betriebszeiten durchgeführt
* @baars_business_2021 ordnen die Extraktion der Filterung zu, da oft nur vorgefilterte Daten übertragen werden, bspw. die letzten 90 Tage oder bestimmte Spalten aus den Rohdaten
* Diese Extrakte werden anschließend bereinigt

## Filterung
### Syntaktische Mängel

* Syntaktische Mängel beziehen sich auf Fehler oder Probleme in der Struktur der Daten, die gegen die Syntax- oder Formatregeln verstoßen
* Syntaktische Mängel sind in der Regel einfacher zu erkennen und automatisch zu beheben, da sie auf klaren Regelverstößen basieren
* Beispiele:
  * Fehlende Werte
  * Widersprüchliche Datumsformate (2022-04-03 und 04.03.2022)
  * Leere Primärschlüssel 
  * Unzulässige Zeichen wie nicht-numerische Zeichen in numerischen Feldern (z.B. "123a" statt "123")

## Filterung
### Was ist ein Primärschlüssel?

:::: {.columns}
::: {.column width="55%"}
* Ein Primärschlüssel ist ein Attribut oder eine Kombination von Attributen, die eindeutig ein Tupel in einer Tabelle identifizieren
* Ein Primärschlüssel darf keine leeren Werte enthalten
* Ein Primärschlüssel darf keine Duplikate enthalten
* Häufig wird ein ID-Feld als Primärschlüssel verwendet
* Wie muss der Primärschlüssel in der Tabelle rechts aussehen?

:::

::: {.column width="45%"}
```{r}

tibble::tibble(
    Vorname = c("Eclipse", "Fantastic", "Crazy", "Crazy", "Harmony", "Omega", "Radiant"),
    Nachname = c("Enigma", "Enigma", "Commander", "Cameleon", "Herald", "Oracle", "Voyager")
) %>% kable(booktabs = TRUE)






```


:::
::::

## Filterung
### Semantische Mängel

* Semantische Mängel beziehen sich auf Probleme in Bezug auf die Bedeutung und Interpretation der Daten
* Daten sind dann inkonsistent sind oder enthalten widersprüchliche Informationen, selbst wenn sie syntaktisch korrekt sind 
* Semantische Mängel erfordern oft ein tieferes Verständnis der Domäne und der Daten, um sie zu identifizieren und zu beheben
* Beispiele: 
  * Negative oder unplausible Werte in Preis-, Alters- oder Umsatzfeldern
  * Nicht-zulässige Postleitzahlen
  * Ungültige IBAN


## Filterung
### Finde die Mängel

```{r}
set.seed(1)
user_data <- tibble(
  `ID (Key)` = c("1", "2", "3", "4", ""),
  Name = c("Jo (h)N", "Mary", "Bob", "Alice", "Tom"),
  Alter = c(25, 30, 40, 18, 19),
  Land = c("DE", "DE", "DE", "DE", "DEU"),
  PLZ = c(2345, 67890, 98765, 54321, 21345),
  Premium = c("TRUE", "FALSE", "TRUE", "1", "FALSE")
) %>% 
  mutate(Geburtsdatum = today( ) - years(Alter) + days(round(runif(5, 10, 30)))) %>% 
  mutate(Geburtsdatum = if_else(Name == "Alice",as_date("2026-04-03"), Geburtsdatum))

kable(user_data, digits = 0)

```

::: {style="font-size: 0.80em"}
1. UserID ist ein Key, leere Werte nicht zugelassen
2. Jo(h)n ist ein Tippfehler
3. Land DEU weicht ab von den anderen Zeilen
4. PLZ 2345 ist nicht gültig, da nur 4 Stellen
5. Premium ist ein boolscher Wert, sollte also TRUE oder FALSE sein und nicht 1
6. Das Geburtsdatum von Alice liegt in der Zukunft
:::
::: {.notes}
1. UserID ist ein Key, NA ist nicht zugelassen
2. Jo(h)n ist ein Tippfehler
3. Land DEU ist nicht der ISO-Code für Deutschland
4. PLZ 2345 ist nicht gültig, da nur 4 Stellen
5. Premium ist ein boolscher Wert, sollte also TRUE oder FALSE sein
6. Das Geburtsdatum von Alice liegt in der Zukunft
:::

## Harmonisierung
### Harmonisierung

* Harmonisierung ist die zweite Schicht der Datentransformation
* Nach Abschluss der Filterungs- und der Harmonisierungsschicht liegt im DWH ein bereinigter und konsistenter Datenbestand auf der festgelegten Granularitätsebene vor
* Dieser ist bereits direkt für Komponenten der Informationsgenerierung nutzbar
* Auch hier wird zwischen syntaktischer und semantischer Harmonisierung unterschieden


## Harmonisierung
### Syntaktische Harmonisierung

* Die operativen Quelldatenbestände weisen meist eine hohe Heterogenität auf und müssen mit Hilfe von umfangreichen Transformationsregeln syntaktisch harmonisiert werden.
* Häufige Gründe sind:
1. Schlüsseldisharmonien
    * Aufgrund verschiedener Primärschlüssel ist die Zusammenführung nicht möglich
    * Beispiel: Kundennummer in System A weist eine führende 0 auf, in System B nicht
    * Oft durch Zuordnungstabellen oder die Generierung neuer Primärschlüssel gelöst


## Harmonisierung
### Syntaktische Harmonisierung

2. Abweichende Kodierung
    * Die Systeme weisen identische Attributnamen auf, haben jedoch unterschiedliche Wertebereiche
    * Beispiel: Geschlecht in System A: "männlich", "weiblich", "divers" und in System B: "m", "w", "d"
3. Synonyme 
    * Attribute haben verschiedene Namen, aber dieselbe Bedeutung
    * Kundennummer in System A und Customer ID in System B
4. Homonyme
    * Attribute haben dieselben Namen, aber verschiedene Bedeutungen 
    * "Business Partner" als Lieferant in A und als Kunde in B

## Harmonisierung
### Semantische Harmonisierung


::: {style="font-size: 0.90em"}
* Die semantische Harmonisierung bezieht sich auf die Vereinheitlichung der fachlichen Bedeutung von Daten
1. Abgleichung fachlicher Kennzahlen
    * Gewährleistet inhaltlich konsistente entscheidungsorientierte Daten
    * Beispiele sind Währungen oder Maßeinheiten oder die Periodenzuordnung betriebswirtschaftlicher Kennzahlen
    * Erfordert hohe Fachkompetenz und ist nicht automatisierbar
2. Granularität
    * Die Überführung der operativen Daten in eine gewünschte Granularität erfordert weitere Transforationsregeln
    * Eine Übersicht tagesaktueller Bestellungen erfordert bspw. die Zusammenfassung aller Transaktionen eines Tages 
:::    

## Aggregation
### Verdichtung und Hierarchisierung

* Die Aggregation dient der Erweiterung der gefilterten und harmonisierten Daten um Verdichtungsstrukturen
* Idealerweise mittels mehrfach verwendbarer, zentraler Dimensionshierarchien, die übergreifende Analysen  unterstützen
* Die Entwicklung dieser Dimensionshierarchietabellen setzt die Antizipation potenzieller Auswertungen voraus 
* Diese Tabellen müssen zudem gepflegt und mit Gültigkeitszeiträumen versehen werden
* Die Erstellung und Pflege von Hierarchietabellen und die Speicherung aggregierter Tabellen ermöglicht erste Anwendungen mit den Daten
* Die physische Speicherung von aggregierten Daten anstelle granularster Ebenen erfolgt hierbei häufig aus Performancegründen

## Anreicherung
### Kennzahlberechnung

* In der Anreicherungsschicht werden fachliche Kennzahlen berechnet und in die Datenbasis integriert. 
* Hier können sowohl Werte auf Basis der harmonisierten Daten der gewünschten Granularität (zweite Schicht) als auch auf Basis der dritten Schicht (bereits aggregierte Tabellen) berechnet  werden. 
* Beispiele sind monatliche Deckungsbeiträge auf Produktebene oder jährliche Deckungsbeiträge auf Filialebene. 

## Anreicherung
### Kennzahlberechnung

* Diese Vorgehensweise hat mehrere Vorteile:
    * Kalkulierbare Reaktionszeigen bei späteren Abfragen aufgrund der Vorausberechnung von Kennzahlen.
    * Garantierte Konsistenz der kalkulierten Werte, da sie anwendungsübergreifend einmalig gebildet und persistiert werden.
    * Etablierung eines abgestimmten betriebswirtschaftlichen Definitionsraumes

## Business Case
### Zurück zu Tofispy

* Tofispy hat uns einen Extrakt aus dem System für Neuregistrierung zur Verfügung gestellt
* Der Datensatz ist bei Superset im Dataset Controlling unter "user_events" hinterlegt, hierbei handelt es sich um den Rohdatensatz, den wir erst einmal transformieren müssen
* Erneuter Startpunkt ist eine explorative Analyse, um die Daten zu verstehen
* In Superset:
  * Oben auf + Chart
  * Dataset "user_events" auswählen
  * Table als Visualisierung auswählen

## Business Case
### Table Visualisierung in Superset


![](img/Superset_Table_Raw.png){width="800" height="500"}

## Business Case
### Table Visualisierung in Superset


![](img/Superset_Table_Raw_2.png){width="800" height="500"}

## Business Case
### Transformationschritte

* Die Daten enthalten mehrere Event-Types und Timestamps
* Welche der Events sind interessant, um User-Wachstum zu verstehen?
* Welche Aggregation des Zeitstempels ist sinnvoll?
* Welche Kennzahlen wollen wir aus den Daten ableiten?




## Quellen