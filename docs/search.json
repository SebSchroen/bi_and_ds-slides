[
  {
    "objectID": "03_VL.html#der-plan-für-heute",
    "href": "03_VL.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung 3\n\n\nQuiz\nDatentransformation:\n\nWas heißt ETL?\nWelche Transformationschritte durchlaufen operative Daten bis zur Speicherung im DWH?\n\nErste Transformationsschritte eines Datensatzes mit User-Events mit Superset"
  },
  {
    "objectID": "03_VL.html#kurzer-überblick-wo-gehts-weiter",
    "href": "03_VL.html#kurzer-überblick-wo-gehts-weiter",
    "title": "Business Intelligence & Data Science",
    "section": "Kurzer Überblick: Wo geht’s weiter?",
    "text": "Kurzer Überblick: Wo geht’s weiter?\nDer ETL Prozess\n\n\n\nBIA Gesamtansatz. Eigene Darstellung in Anlehnung an Baars und Kemper (2021)."
  },
  {
    "objectID": "03_VL.html#etl-prozess",
    "href": "03_VL.html#etl-prozess",
    "title": "Business Intelligence & Data Science",
    "section": "ETL Prozess",
    "text": "ETL Prozess\nWas ist ETL?\n\nETL steht für Extract, Transform, Load oder auch Extraktion, Transformation, Laden\nExtraktion beschreibt die Übertragung der Daten aus den operativen Quellsystemen in einen Arbeitsbereich, oft Staging Area genannt\nHier erfolgt die Transformation, die wiederum aus vier Teilschritten besteht:\n\nFilterung\nHarmonisierung\nAggregation\nAnreicherung\n\nAnschließend werden die bereinigten und aufbereiteten Daten in die Zieldatenbank geladen"
  },
  {
    "objectID": "03_VL.html#etl-prozess-1",
    "href": "03_VL.html#etl-prozess-1",
    "title": "Business Intelligence & Data Science",
    "section": "ETL Prozess",
    "text": "ETL Prozess\nTeilschritte der Transformation\n\n\n\n\nTeilprozesse im ETL-Prozess. Eigene Darstellung in Anlehnung an Baars und Kemper (2021)"
  },
  {
    "objectID": "03_VL.html#filterung",
    "href": "03_VL.html#filterung",
    "title": "Business Intelligence & Data Science",
    "section": "Filterung",
    "text": "Filterung\nExtraktion und erste Bereinigung\n\nFilterung umfasst die Extraktion aus operativen Daten und die Bereinigung syntaktischer und semantischer Defekte in den Rohdaten\nDie Extraktion erfolgt vielfältig, z.B. über Flat File Transporte oder API Schnittstellen\nAus Performance-Erwärgungen wird die Extraktion mittels geplanter Batch-Jobs oft außerhalb der Betriebszeiten durchgeführt\nBaars und Kemper (2021) ordnen die Extraktion der Filterung zu, da oft nur vorgefilterte Daten übertragen werden, bspw. die letzten 90 Tage oder bestimmte Spalten aus den Rohdaten\nDiese Extrakte werden anschließend bereinigt"
  },
  {
    "objectID": "03_VL.html#filterung-1",
    "href": "03_VL.html#filterung-1",
    "title": "Business Intelligence & Data Science",
    "section": "Filterung",
    "text": "Filterung\nSyntaktische Mängel\n\nSyntaktische Mängel beziehen sich auf Fehler oder Probleme in der Struktur der Daten, die gegen die Syntax- oder Formatregeln verstoßen\nSyntaktische Mängel sind in der Regel einfacher zu erkennen und automatisch zu beheben, da sie auf klaren Regelverstößen basieren\nBeispiele:\n\nFehlende Werte\nWidersprüchliche Datumsformate (2022-04-03 und 04.03.2022)\nLeere Primärschlüssel\nUnzulässige Zeichen wie nicht-numerische Zeichen in numerischen Feldern (z.B. “123a” statt “123”)"
  },
  {
    "objectID": "03_VL.html#filterung-2",
    "href": "03_VL.html#filterung-2",
    "title": "Business Intelligence & Data Science",
    "section": "Filterung",
    "text": "Filterung\nSemantische Mängel\n\nSemantische Mängel beziehen sich auf Probleme in Bezug auf die Bedeutung und Interpretation der Daten\nDaten sind dann inkonsistent sind oder enthalten widersprüchliche Informationen, selbst wenn sie syntaktisch korrekt sind\nSemantische Mängel erfordern oft ein tieferes Verständnis der Domäne und der Daten, um sie zu identifizieren und zu beheben\nBeispiele:\n\nNegative oder unplausible Werte in Preis-, Alters- oder Umsatzfeldern\nNicht-zulässige Postleitzahlen\nUngültige IBAN"
  },
  {
    "objectID": "03_VL.html#harmonisierung",
    "href": "03_VL.html#harmonisierung",
    "title": "Business Intelligence & Data Science",
    "section": "Harmonisierung",
    "text": "Harmonisierung\nHarmonisierung\n\nHarmonisierung ist die zweite Schicht der Datentransformation\nNach Abschluss der Filterungs- und der Harmonisierungsschicht liegt im DWH ein bereinigter und konsistenter Datenbestand auf der festgelegten Granularitätsebene vor\nDieser ist bereits direkt für Komponenten der Informationsgenerierung nutzbar\nAuch hier wird zwischen syntaktischer und semantischer Harmonisierung unterschieden"
  },
  {
    "objectID": "03_VL.html#harmonisierung-2",
    "href": "03_VL.html#harmonisierung-2",
    "title": "Business Intelligence & Data Science",
    "section": "Harmonisierung",
    "text": "Harmonisierung\nSyntaktische Harmonisierung\n\nDie operativen Quelldatenbestände weisen meist eine hohe Heterogenität auf und müssen mit Hilfe von umfangreichen Transformationsregeln syntaktisch harmonisiert werden.\nHäufige Gründe sind:\n\n\nSchlüsseldisharmonien\n\nAufgrund verschiedener Primärschlüssel ist die Zusammenführung nicht möglich\nBeispiel: Kundennummer in System A weist eine führende 0 auf, in System B nicht\nOft durch Zuordnungstabellen oder die Generierung neuer Primärschlüssel gelöst"
  },
  {
    "objectID": "03_VL.html#harmonisierung-3",
    "href": "03_VL.html#harmonisierung-3",
    "title": "Business Intelligence & Data Science",
    "section": "Harmonisierung",
    "text": "Harmonisierung\nSyntaktische Harmonisierung\n\nAbweichende Kodierung\n\nDie Systeme weisen identische Attributnamen auf, haben jedoch unterschiedliche Wertebereiche\nBeispiel: Geschlecht in System A: “männlich”, “weiblich”, “divers” und in System B: “m”, “w”, “d”\n\nSynonyme\n\nAttribute haben verschiedene Namen, aber dieselbe Bedeutung\nKundennummer in System A und Customer ID in System B\n\nHomonyme\n\nAttribute haben dieselben Namen, aber verschiedene Bedeutungen\n“Business Partner” als Lieferant in A und als Kunde in B"
  },
  {
    "objectID": "03_VL.html#harmonisierung-4",
    "href": "03_VL.html#harmonisierung-4",
    "title": "Business Intelligence & Data Science",
    "section": "Harmonisierung",
    "text": "Harmonisierung\nSemantische Harmonisierung\n\n\nDie semantische Harmonisierung bezieht sich auf die Vereinheitlichung der fachlichen Bedeutung von Daten\n\n\nAbgleichung fachlicher Kennzahlen\n\nGewährleistet inhaltlich konsistente entscheidungsorientierte Daten\nBeispiele sind Währungen oder Maßeinheiten oder die Periodenzuordnung betriebswirtschaftlicher Kennzahlen\nErfordert hohe Fachkompetenz und ist nicht automatisierbar\n\nGranularität\n\nDie Überführung der operativen Daten in eine gewünschte Granularität erfordert weitere Transforationsregeln\nEine Übersicht tagesaktueller Bestellungen erfordert bspw. die Zusammenfassung aller Transaktionen eines Tages"
  },
  {
    "objectID": "03_VL.html#aggregation",
    "href": "03_VL.html#aggregation",
    "title": "Business Intelligence & Data Science",
    "section": "Aggregation",
    "text": "Aggregation\nVerdichtung und Hierarchisierung\n\nDie Aggregation dient der Erweiterung der gefilterten und harmonisierten Daten um Verdichtungsstrukturen\nIdealerweise mittels mehrfach verwendbarer, zentraler Dimensionshierarchien, die übergreifende Analysen unterstützen\nDie Entwicklung dieser Dimensionshierarchietabellen setzt die Antizipation potenzieller Auswertungen voraus\nDiese Tabellen müssen zudem gepflegt und mit Gültigkeitszeiträumen versehen werden\nDie Erstellung und Pflege von Hierarchietabellen und die Speicherung aggregierter Tabellen ermöglicht erste Anwendungen mit den Daten\nDie physische Speicherung von aggregierten Daten anstelle granularster Ebenen erfolgt hierbei häufig aus Performancegründen"
  },
  {
    "objectID": "03_VL.html#anreicherung",
    "href": "03_VL.html#anreicherung",
    "title": "Business Intelligence & Data Science",
    "section": "Anreicherung",
    "text": "Anreicherung\nKennzahlberechnung\n\nIn der Anreicherungsschicht werden fachliche Kennzahlen berechnet und in die Datenbasis integriert.\nHier können sowohl Werte auf Basis der harmonisierten Daten der gewünschten Granularität (zweite Schicht) als auch auf Basis der dritten Schicht (bereits aggregierte Tabellen) berechnet werden.\nBeispiele sind monatliche Deckungsbeiträge auf Produktebene oder jährliche Deckungsbeiträge auf Filialebene."
  },
  {
    "objectID": "03_VL.html#anreicherung-1",
    "href": "03_VL.html#anreicherung-1",
    "title": "Business Intelligence & Data Science",
    "section": "Anreicherung",
    "text": "Anreicherung\nKennzahlberechnung\n\nDiese Vorgehensweise hat mehrere Vorteile:\n\nKalkulierbare Reaktionszeigen bei späteren Abfragen aufgrund der Vorausberechnung von Kennzahlen.\nGarantierte Konsistenz der kalkulierten Werte, da sie anwendungsübergreifend einmalig gebildet und persistiert werden.\nEtablierung eines abgestimmten betriebswirtschaftlichen Definitionsraumes"
  },
  {
    "objectID": "03_VL.html#quellen",
    "href": "03_VL.html#quellen",
    "title": "Business Intelligence & Data Science",
    "section": "Quellen",
    "text": "Quellen\n\n\nBusiness Intelligence & Data Science, SoSe 2024\n\n\n\nBaars, Henning, und Hans-Georg Kemper. 2021. Business Intelligence & Analytics: Grundlagen und praktische Anwendungen: Ansätze der IT-basierten Entscheidungsunterstützung. 4., überarbeitete und erweiterte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Vieweg."
  },
  {
    "objectID": "02_VL.html#der-plan-für-heute",
    "href": "02_VL.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung 2\n\nDatenbereitstellung:\n\nData Warehouse\nData Mart\nArchitekturkonzepte\n\nBusiness Case: Der Musikstreaming Anbieter Tofispy braucht unsere Hilfe\nVerknüpfung eines ersten Data Marts mit Superset oder Datenanalyse mit Excel"
  },
  {
    "objectID": "02_VL.html#überblick-zum-bia-gesamteinsatz",
    "href": "02_VL.html#überblick-zum-bia-gesamteinsatz",
    "title": "Business Intelligence & Data Science",
    "section": "Überblick zum BIA Gesamteinsatz",
    "text": "Überblick zum BIA Gesamteinsatz\nDatenbereitstellung\n\n\n\nBIA Gesamtansatz. Eigene Darstellung in Anlehnung an Baars und Kemper (2021)."
  },
  {
    "objectID": "02_VL.html#data-warehouse",
    "href": "02_VL.html#data-warehouse",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nBegriff\n\n\n\n\n\n\nDefinition\n\n\nEin Data Warehouse (DWH) ist ein Datenhaltungssystem dispositiver Daten, das von den operativen Datenbeständen getrennt, themenorientiert aufbereitet und logisch zentralisiert ist. Ein DWH integriert unternehmensweit Datenbestände aus verschiedenen operativen internen Systemen (z.B. Kernbanksystemen und Enterprise-Ressource-Planning-Systemen) sowie externen Systemen (z.B. Börseninformationssystemen und Systeme für externe Ratings) und dient idealtypisch als unternehmensweite, einheitliche und konsistente Datenbasis für alle Arten von Systemen der Entscheidungsunterstützung (siehe Kemper und Sun 2023).\n\n\n\n\n\nDie entscheidenden Punkte sind hier:\n\nTrennung von operativen und dispositiven Daten\nIntegration von Datenbeständen aus verschiedenen und oftmals sehr heterogenen Quellen\nEinheitliche und konsistente Datenbasis für das gesamte Unternehmen"
  },
  {
    "objectID": "02_VL.html#data-warehouse-1",
    "href": "02_VL.html#data-warehouse-1",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nEigenschaften\n\n\n\nThemenorientierung:\n\nDispositive Daten des DWH sind explizit an den Interessenslagen der Entscheidenden ausgerichtet\nDie operativen bzw. externen Daten werden vor der Speicherung im DWH aufbereitet, harmonisiert und ggf. voraggregiert\nThemen sind Produkthierarchien, vordefinierte Zeiträume wie Quartale oder betriebswirtschaftliche Kennzahlen wie DB1\n\nIntegration:\n\nDaten aus den unterschiedlichen operativen und externen Systemen werden im DWH integriert\nZusammenführung zu einer inhaltlich widerspruchfreien Datenquelle, sogenannter “single point of truth”"
  },
  {
    "objectID": "02_VL.html#data-warehouse-2",
    "href": "02_VL.html#data-warehouse-2",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nEigenschaften\n\n\nZeitraumbezug:\n\nOperative Systeme sind transaktionsorientiert und bilden einen bestimmten Zeitpunkt ab\nDaten im DWH werden üblicherweise auf Zeiträume aggregiert, bspw. ein Monat oder ein Jahr\n\nNicht-Volatilität:\n\nDaten im DWH werden dauerhaft abgelegt und für die Analyse zur Verfügung gestellt\nDWH-Daten werden somit in der Regel nicht mehr geändert, überschrieben oder entfernt"
  },
  {
    "objectID": "02_VL.html#data-warehouse-3",
    "href": "02_VL.html#data-warehouse-3",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nKomponenten des Data Warehouse\n\n\n\nData Mart\n\nSeparater Datenpool für einen bestimmten Anwendungsbereich spezifischer Abteilungen\nNur ein Ausschnitt aus dem gesamten Datenpool, häufig aus Performance-Erwägungen\nHäufig mit Reporting- und OLAP assoziiert, zunehmend aber auch für Analysen\n\n\nCore Data Warehouse\n\nRückrat der meisten Architekturkonzepte und oft als Basisdatenbank bezeichnet\nBefüllung über ETL-Prozesse aus operativen Quellsystemen\nMeist auf relationalen Datenhaltungssystemen basierend mit großen Datenvolumina (TB Bereich)\nApplikationsneutral modelliert"
  },
  {
    "objectID": "02_VL.html#data-warehouse-4",
    "href": "02_VL.html#data-warehouse-4",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nFunktionen des CDWH\n\nSammel- und Integrationsfunktion:\n\n\n\nAufnahme aller wichtigen Daten für die Analyse in Form eines zentralen Datenlagers\n\n\n\nDistributionsfunktion:\n\n\n\nVersorgung aller nachgeschalteten Data Marts mit Daten\n\n\n\nQualitätssicherungsfunktion:\n\n\n\nDatentransformation sichert die syntaktische und semantische Stimmigkeit der dispositiven Datenbasis"
  },
  {
    "objectID": "02_VL.html#data-warehouse-5",
    "href": "02_VL.html#data-warehouse-5",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nData Mart vs. CDWH\n\n\n\nCharakteristika von Data Mart und Core Data Warehouse im Vergleich. In Anlehnung an Baars und Kemper (2021)\n\n\n\n\n\n\n\n\nData Mart\nCore Data Warehouse\n\n\n\n\nZiel\nEntscheidungsunterstützung für ausgewählte Bereiche, spezifisch auf Analyseanforderungen zugeschnitten\nEntscheidungsunterstützung für alle Bereiche in einem Unternehmen\n\n\nAusrichtung\nBereichsspezifisch oder Abteilungsbezogen\nZentral und unternehmensweit\n\n\nGranularität\nHöhere Aggregationen\nFeinste verfügbare Granularität\n\n\nVerfügbarkeit für Endanwendende\nIn der Regel möglich\nHäufig nicht erlaubt da zentral durch IT betrieben und als Quellsystem für Marts genutzt\n\n\nFlexibilität der Analysen\nTendenziell gering und auf Anwendungsbereich beschränkt\nSehr flexibel\n\n\nVolumina\nGering bis moderat\nModerat bis umfangreich"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen",
    "href": "02_VL.html#dwh-architekturen",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nUnabhängige Data Marts\n\n\n\n\n\n\n\n\nUnabhängige Data Marts. Eigene Darstellung in Anlehnung an Hahne (2016)\n\n\n\n\n\n\nAuch Stove-Pipe Ansatz\nBedienen sich direkt aus den operativen und externen Systemen\nBereiten die enthaltenen Daten für relevante Anwendungsfelder auf\nDaten werden isoliert bezogen und fließen direkt in Datensilos auf Basis bereichsspezifischer Fragestellungen\nVerschiedene Marts können unterschiedliche externe Datenquellen zusammenführen\n\n\n\n\n\n\nStove-Pipe Ansatz heißt so viel wie Ofenrohr, also eine direkte Verbindung zwischen Quelle und Ziel"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-1",
    "href": "02_VL.html#dwh-architekturen-1",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nUnabhängige Data Marts\n\n\n\nVorteile:\n\nSchnelle und bereichsspezifische Informationsbereitstellung\nSinnvoll bei fehlender Governance Strategie\nErfüllung maßgeschneideter bereichsspezifischer Fragestellungen\n\n\nNachteile:\n\nHäufig historisch gewachsene Strukturen und damit geringe Governance\nMehrfache Aufbereitung der Quelldaten\nGefahr von Inkonsistenzen bei der Kennzahlenberechnung zwischen Marts\nMangelnde Möglichkeit bereichsübergreifender Analysen"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-2",
    "href": "02_VL.html#dwh-architekturen-2",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nAbgestimmte Data Marts\n\n\n\n\n\n\n\nAbhängige Data Marts. Eigene Darstellung in Anlehnung an Hahne (2016)\n\n\n\n\n\n\nKonzeptionell abgestimmte Datenmodelle um die Integrität des Datenmaterials zu gewährleisten\nDas abgestimmte Datenmodell dient der syntaktischen und semantischen Vereinheitlichung\nInhaltliche und zeitliche Übereinstimmung der Datenextraktionen ist entscheidend für die Konsistenz der Data Marts"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-3",
    "href": "02_VL.html#dwh-architekturen-3",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nAbgestimmte Data Marts\n\n\n\nVorteile:\n\nIntegrität des Datenmodells wird gewährleistet\nMöglichkeit bereichsübergreifender Analysen bei hoher Flexibilität innerhalb der Bereiche\nEntscheidungsunterstützung für alle Bereiche in einem Unternehmen\n\n\nNachteile:\n\nDurch hohen Bereichsbezug oft unterschiedliche Granularität oder Aufbereitung, damit nur bedingte Integration zwischen Marts\nMöglicherweise höherer Abstimmungsbedarf zwischen Abteilungen bei der Kennzahldefinition\nInformationsverlust bei übergreifenden Analysen"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-4",
    "href": "02_VL.html#dwh-architekturen-4",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse\n\n\n\n\n\n\n\nCore Data Warehouse. Eigene Darstellung in Anlehnung an Hahne (2016)\n\n\n\n\n\n\nDas CDWH wird direkt aus den operativen Quellsystemen befüllt und basiert auf einer relationalen Datenbank\nDieser Ansatz wird oft als Monolith bezeichnet\nDie Daten decken unterschiedliche Auswertungszwecke ab und sind weniger anwendungsbezogen als Datensilos"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-5",
    "href": "02_VL.html#dwh-architekturen-5",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse\n\n\n\nVorteile:\n\nHoher Grad an Mehrfachverwendbarkeit der Daten\nHoher Detailgrad möglich\nBei kleineren Anwendungsfällen oft ausreichend\n\n\nNachteile:\n\nBerechtigungsmanagement und Performance stoßen bei komplexen Anwendungsfällen schnell an Grenzen\nBei größeren Einheiten mit eigenen Geschäftsprozessen und stark abweichenden Hierarchiestrukturen sehr komplex, hier bietet sich der Einsatz mehrerer CDWH an"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-6",
    "href": "02_VL.html#dwh-architekturen-6",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse mit abhängigen Data Marts\n\n\n\n\nAuch Hub-and-Spoke Ansatz genannt\nCDWH wird nicht direkt für Analysen herangezogen, sondern dient der Befüllung von Marts\nMarts sind dann anwendungsbezogen, weisen aber ein einheitliches Datenmodell auf\nCDWH als Hub erfüllt Aufgaben der Integration, Qualitätssicherung und Datenverteilung an die Marts\n\n\n\n\n\n\n\n\nCore Data Warehouse mit abhängigen Data Marts. Eigene Darstellung in Anlehnung an Hahne (2016)"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-7",
    "href": "02_VL.html#dwh-architekturen-7",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse mit abhängigen Data Marts\n\n\n\nVorteile:\n\nEinmaliger und einheitlicher Transformationsprozess ohne redundante Transformationslogik\nGeringere Anzahl an Extraktionsprozessen\nReduzierte Anzahl direkter Schnittstellen zwischen Marts und operativen Daten\n\n\nNachteile:\n\nNach wie vor eher traditionelle BI-Sicht"
  },
  {
    "objectID": "02_VL.html#dwh-architekturen-8",
    "href": "02_VL.html#dwh-architekturen-8",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nArchitekturen-Mix\n\n\n\n\n\nArchitekturen-Mix. Eigene Darstellung in Anlehnung an Hahne (2016)"
  },
  {
    "objectID": "02_VL.html#business-case",
    "href": "02_VL.html#business-case",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nDas Wachstum bei Tofispy stagniert\n\n\n\nTofispy ist ein Musikstreaming Anbieter aus Deutschland\nDas Unternehmen kämpft mit stagnierendem Wachstum\nWir – die Unternehmensberatung LeinbizConsult – wurden beauftragt, die Gründe für das stagnierende Wachstum zu identifizieren und Handlungsempfehlungen zu entwickeln\nDie Geschäftsführung hat uns erste Daten zur Verfügung gestellt, um die aktuelle Situation zu evaluieren und Ursachenforschung zu betreiben"
  },
  {
    "objectID": "02_VL.html#business-case-1",
    "href": "02_VL.html#business-case-1",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nDatensatz\n\nÜberblick über den Streamingmarkt:\n\nTabelle “market_share”\nAnzahl der Nutzer pro Plattform in Mio\nDaten von 2016 bis 2024\nDie Daten für 2024 sind eine Hochrechnung für das laufende Jahr"
  },
  {
    "objectID": "02_VL.html#business-case-2",
    "href": "02_VL.html#business-case-2",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nAufgabe\n\n\nArbeit in 2er Teams mit mindestens einem Laptop oder Tablet (nicht ideal für Excel) pro Team\nJedes Team lädt die Daten bei StudIP herunter und diskutiert untereinander, wie die Daten strukturiert sind\nTrial & Error in Superset mit Hilfe der Dokumentation:\n\nDokumentation unter preset.io\nStartpunkt: Creating a Chart (in der preset Doku)\nTable als Ausgangspunkt für explorative Analyse\n\nAnschließend Analyse in Excel + Superset und kritische Gegenüberstellung der beiden Ansätze"
  },
  {
    "objectID": "02_VL.html#business-case-3",
    "href": "02_VL.html#business-case-3",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nFragen\n\n\nWas sind die Vorteile der beiden Ansätze?\nWächst Tofispy schneller oder langsamer als der Gesamtmarkt?\nWie hoch ist der Marktanteil am Ende von 2024 voraussichtlich?\nWelcher Konkurrent wächst am stärksten?\nIst der Datensatz operativ oder dispositiv?\nWelcher Reifegrad von Analytics liegt vor?"
  },
  {
    "objectID": "02_VL.html#hausaufgabe",
    "href": "02_VL.html#hausaufgabe",
    "title": "Business Intelligence & Data Science",
    "section": "Hausaufgabe",
    "text": "Hausaufgabe\nVideo anschauen\n\nLink zum Video"
  },
  {
    "objectID": "02_VL.html#hausaufgabe-1",
    "href": "02_VL.html#hausaufgabe-1",
    "title": "Business Intelligence & Data Science",
    "section": "Hausaufgabe",
    "text": "Hausaufgabe\nFragen zu Superset\n\nWas sind Dimensions und Metrics? Welchen Zweck haben sie?\nWas ist der Unterschied zwischen einem Dataset und einer Database?\nWas ist der Unterschied zwischen Superset und Preset?"
  },
  {
    "objectID": "02_VL.html#quellen",
    "href": "02_VL.html#quellen",
    "title": "Business Intelligence & Data Science",
    "section": "Quellen",
    "text": "Quellen\n\n\nBusiness Intelligence & Data Science, SoSe 2024\n\n\n\nBaars, Henning, und Hans-Georg Kemper. 2021. Business Intelligence & Analytics: Grundlagen und praktische Anwendungen: Ansätze der IT-basierten Entscheidungsunterstützung. 4., überarbeitete und erweiterte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Vieweg.\n\n\nHahne, Michael. 2016. „Architekturkonzepte und Modellierungsverfahren für BI-Systeme“. In Analytische Informationssysteme, herausgegeben von Peter Gluchowski und Peter Chamoni, 147–85. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-47763-2_8.\n\n\nKemper, Hans-Georg, und Xuanpu Sun. 2023. „Data Warehouse“. In Gabler Bankenlexikon. https://www.gabler-banklexikon.de/definition/data-warehouse-56847/version-377924."
  },
  {
    "objectID": "01_VL_D.html#der-plan-für-heute",
    "href": "01_VL_D.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung 1\n\n\nVorstellung & kurzes Kennenlern-Quiz\nOrganisatorisches\nEinleitung:\n\nWas sind Business Intelligence & Data Science?\nWas sind operative und dispositive Daten?\nWie werden aus operativen Daten entscheidungsrelevante Informationen?\n\nErster Login bei unserem BI-Tool Superset\nDatenexploration in Superset\n\n\n\n\nWir starten mit einer kurzen Vorstellung, in der ich mich kurz vorstelle und anschließend gibt es ein kurzes Quiz, das einerseits Quizzes als Tool einführt, mit dem wir künftig die Doppelblöcke eröffnet und mir andererseits die Gelegenheit gibt, den Wissenstand abzuklopfn\nDann folgt ein Stresstest für unser BI-Tool Apache Superset, das wir künftig für die Visualisierung von Daten nutzen werden, indem wir uns alle gleichzeitig einloggen und testen, ob das System der Last standhält\nHiernach folgen ein paar organisatorische Hinweise, bevor wir in die inhaltliche Einführung starten:\n\nWas ist das eigentlich, Business Intelligence und Data Science?\nWie werden Informationen aus operativen Daten gewonnen?"
  },
  {
    "objectID": "01_VL_D.html#vorstellung",
    "href": "01_VL_D.html#vorstellung",
    "title": "Business Intelligence & Data Science",
    "section": "Vorstellung",
    "text": "Vorstellung\nKennenlern-Quiz\n\n\nDas Kennenlern-Quiz umfasst Fragen zu Vorkenntnissen rund um BI-Software und R, um ein Gefühl für den Wissensstand zu bekommen.\nAußerdem gibt es wichtige Fachfragen rund um BI und Data Science.\nDie Gewinnerin/Der Gewinner erhält einen überragenden Preis\nAls Plattform dient Quizziz.com, es ist keine Registrierung notwendig, Verwendung über Smartphone und Laptop möglich\nKünftig starten wir einen Doppelblock mit einem Quiz zum vorangeganenen Block mit einem kleinen Preis für den Tagessieg"
  },
  {
    "objectID": "01_VL_D.html#warum-bi-und-data-science",
    "href": "01_VL_D.html#warum-bi-und-data-science",
    "title": "Business Intelligence & Data Science",
    "section": "Warum BI und Data Science?",
    "text": "Warum BI und Data Science?\nEntscheidende Skills für die berufliche Zukunft\n\n\n\nQuelle: McKinsey\n\n\n\n\nDie Grafik zeigt die sogenannten Delta Skills nach McKinsey, das sind jene Fähigkeiten, die einen Unterschied machen werden, um in der Arbeitswelt der Zukunft erfolgreich zu sein.\nDie Kategorien sind: Kognitiv, Interpersonell, Selbstführung und Digital\nUnser FOkus ist die Kategorie Digital, die sich wiederum in die Bereiche Digital Fluency, Software Nutzung und Entwicklung sowie Verständnis digitaler Systeme aufteilt.\nWas ist digital Fluency? Es ist die Fähigkeit, digitale Tools und Technologien zu nutzen und hier Digital Learning und Collaboration besonders wichtig.\nSoftware Nutzung und Entwicklung umfasst insbesondere Programming und Datenanalyse, insbesondere den zweiten Punkt werden wir sehr ausführlich im Methodenteil zu Data Science behandeln.\nZiel ist hier nicht, in wenigen Blöcken eine vollwertige Ausbildung in diesem Bereich zu ersetzen, sondern vielmehr das Big Picture zu vermitteln, um im Unternehmen als guter Sparringspartner für Data Science Themen und Projekte zu fungieren.\nProgramming wird eher nebenbei mit einfließen\nEin entscheidender Punkt ist unten rechts die Data Literacy. Das umfasst die Fähigkeit, Daten zu lesen, zu interpretieren und zu kommunizieren. Das ist ein zentraler Punkt, den wir in dieser Vorlesung adressieren werden. Meines Erachtens der größte Knackpunkt im Unternehmensumfeld, da hier die größte Lücke zwischen den Fachbereichen und der IT besteht."
  },
  {
    "objectID": "01_VL_D.html#warum-bi-und-data-science-1",
    "href": "01_VL_D.html#warum-bi-und-data-science-1",
    "title": "Business Intelligence & Data Science",
    "section": "Warum BI und Data Science?",
    "text": "Warum BI und Data Science?\nTechnologische Kompetenzen\n\n\n\nLink zur Quelle\n\n\n\n\nDie Grafik zeigt die Ergebnisse einer Studie des Stifterverbands, die sich mit den zukünftigen Anforderungen an die Arbeitswelt befasst.\nEs handelt sich hier um eine Umfrage und die Grafik gibt den Anteil der teilnehmenden an, welche die gegeben Aspekte jetzt und in 5 Jahren als wichtig erachten.\nFür uns wichtig sind IT-Architektur und Data Analytics & KI\nDie Vorlesung wird einige Architektur-Komponenten umfassen, nämlich den Aufbau einer BI-Architektur und eine Einbettung ins Unternehmen allgemein\nData Analytics und KI umfasst die Methoden, die wir in der zweiten Hälfte der Vorlesung behandeln werden, wobei der Fokus weniger auf KI liegt und mehr auf den Data Science Methoden, die vielen KI-Technologien zu Grunde liegen"
  },
  {
    "objectID": "01_VL_D.html#kursaufbau",
    "href": "01_VL_D.html#kursaufbau",
    "title": "Business Intelligence & Data Science",
    "section": "Kursaufbau",
    "text": "Kursaufbau\nZeitplan Gruppe D\n\n\n\n\n\nBlock\nGruppe D\nThema\n\n\n\n\n1\n21.03.2024:09:00 – 10:30\nOrganisation, Einleitung\n\n\n2\n21.03.2024:10:45 – 12:15\nDatenbereitstellung: Data Warehousing\n\n\n3\n28.03.2024:13:00 – 14:30\nDatentransformation\n\n\n4\n28.03.2024:14:45 – 16:15\nBig Data und Data Lake\n\n\n5\n02.04.2024:13:00 – 14:30\nInformationsgenerierung: Berichtsorientierte Analysen\n\n\n6\n02.04.2024:14:45 – 16:15\nAdvanced und Predictive Analytics: Grundlagen\n\n\n7\n15.04.2024:13:00 – 14:30\nAdvanced und Predictive Analytics: Klassifikation\n\n\n8\n15.04.2024:14:45 – 16:15\nAdvanced und Predictive Analytics: Klassifikation\n\n\n9\n02.05.2024:13:00 – 14:30\nInformationsbereitstellung: Visualisierungstechniken\n\n\n10\n02.05.2024:14:45 – 16:15\nWild Card: Wunschthema oder Restinhalte und Q\\&A\n\n\n-\n13.05.2024:13:00 – 14:30\nKlausur (60 Minuten)"
  },
  {
    "objectID": "01_VL_D.html#kursmaterialen",
    "href": "01_VL_D.html#kursmaterialen",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialen",
    "text": "Kursmaterialen\nKurs-Website\n\nAlle Kursinhalte sind auf der Kurs-Website verfügbar:\n\nhttps://sebschroen.github.io/bi_and_ds-lecture_notes/\n\n\n\n\nAktuell passwortgeschützt aufgrund Nutzung Copyright-geschützter Materialien, daher nur Nutzung in diesem Personenkreis\n3 gefundene und gemeldete Typos (E-Mail, StudIP) = 1 Packung Bahlsen-Kekse nach Wahl\nTipp: Bookmark des Links nach Passworteingabe erübrigt künftige Eingabe des Passworts\n\n\n\n\nPasswort anschreiben\nEinfach zusammen durchklicken und kurz Zeit zur Orientierung geben, Trick zum Bookmark zeigen"
  },
  {
    "objectID": "01_VL_D.html#kursmaterialen-1",
    "href": "01_VL_D.html#kursmaterialen-1",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialen",
    "text": "Kursmaterialen\nFolien\n\n\nFolien sind auf der Startseite der Kurs-Website verlinkt\nDarstellung ist für den Browser (Chrome, Safari und Firefox) optimiert, um interaktive Elemente darzustellen\nIm Burger-Menü oben rechts lässt sich zu jeder Zeit auch eine PDF Version zum Ausdruck in Papierform oder für Notizen erstellen:\n\nTools -&gt; PDF Export Mode -&gt; Strg + P (Cmd + P) -&gt; Druck als PDF\n\nDie Folien werden rechtzeitig vor der Vorlesung als PDF auf StudIP hochgeladen\nInteraktive Elemente werden separat verlinkt.\n\n\n\n\nDie Folien sind im Ablaufplan auf der Startseite in aktueller Fassung verlinkt und lassen sich auf mehreren Wegen darstellen.\n\n\nKonzipiert sind die Folien für die Darstellung im Browser, um interaktive Elemente darzustellen.\nIm Menü oben rechts lässt sich zu jeder Zeit auch eine PDF Version zum Ausdrucken in Papierform erstellen oder zur Darstellung auf Endgeräten, auf denen Sie Notizen machen möchten.\nAm Ende jeder Vorlesung wird die finale Fassung der Folien auf StudIP im PDF Format hochgeladen.\nDie HTML Fassung bleibt verfügbar."
  },
  {
    "objectID": "01_VL_D.html#kursmaterialen-2",
    "href": "01_VL_D.html#kursmaterialen-2",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialen",
    "text": "Kursmaterialen\nPDF-Skript\n\nNeben der HTML-Version ist auch ein PDF-Skript verfügbar und kann auf der Startseite heruntergeladen werden\nDie PDF-Version entspricht inhaltlich immer der Website\nDie Darstellung ist für HTML optimiert und kann für Artefakte beim PDF Rendering sorgen, erleichtert aber das Ausdrucken\n\n\n\nDie PDF-Version zum Skript ist auf der Startseite der Website verlinkt und entspricht inhaltlich immer der Website.\nDie Darstellung ist für html optimiert und kann für Artefakte beim PDF Rendering sorgen, erleichtert aber das Ausdrucken"
  },
  {
    "objectID": "01_VL_D.html#kursmaterialien",
    "href": "01_VL_D.html#kursmaterialien",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialien",
    "text": "Kursmaterialien\nErgänzende Literatur\n\n\n\nAlle klausurrelevanten Inhalte lassen sich auf der Kurs-Website finden und nachlesen, zusätzliche Literatur ist nicht notwendig\nDer Aufbau des Kurses richtet sich nach dem Lehrbuch Business Intelligence & Analytics - Grundlagen und praktische Anwendungen, 4. Auflage von Henning Baars und Hans-Georg Kemper\nDas Buch ist über die Bibliothek der Leibniz FH als E-Book verfügbar\nBlock 1 - 5 entstammen größtenteils in Baars und Kemper (2021)\nMethodische Aspekte rund um Predictive Analytics entstammen größtenteils dem frei verfügbaren Introduction to Statistical Learning, 2. Auflage von Gareth James, Daniela Witten, Trevor Hastie und Robert Tibshirani\nDie Quellen zu jeder Vorlesung sind jeweils auf der letzten Folien angegeben."
  },
  {
    "objectID": "01_VL_D.html#business-intelligence",
    "href": "01_VL_D.html#business-intelligence",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence",
    "text": "Business Intelligence\nBegriffsabgrenzung\n\n\n\n\n\n\nDefinition\n\n\nBusiness Intelligence (BI) ist eine Reihe von Architekturen und Technologien, die Rohdaten in sinnvolle und nutzbare, entscheidungsrelevante Informationen umwandeln. Es ermöglicht Anwendenden, informierte Entscheidungen auf der Grundlage von Daten zu treffen, die ein Unternehmen gegenüber seinen Wettbewerbern in Vorteil bringen können (siehe Forrester.com).\n\n\n\n\n\nAbgeleitet vom Intelligence-Begriff in der militärischen Informationsverarbeitung Großbritanniens im 2. Weltkrieg:\n\nDie richtigen Informationen zur richtigen Zeit an die richtigen Personen.\n\nFrühe kommerzielle Ansätze in den 60er Jahren im Zuge der Entwicklung relationaler Datenbanken."
  },
  {
    "objectID": "01_VL_D.html#business-intelligence-1",
    "href": "01_VL_D.html#business-intelligence-1",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence",
    "text": "Business Intelligence\nBegriffsabgrenzung\n\n\nZunächst Fokus auf Management Support Systeme (MSS) und daher eher auf oberste Ebenen zugeschnitten\nDer Begriff Business Intelligence (BI) wurde in den 1990ern geprägt\nHeute wird BI laut Gartner Group charakterisiert durch:\n\nBreite Verfügbarkeit von BI Tools auf allen Ebenen des Unternehmens\nGeschäftsentscheidung auf Basis aktueller Informationen und Daten und nicht auf Intuition\nUmfangreiche Analyse- und Reportingmöglichkeiten mit Self-Service Tools für Fachbereiche"
  },
  {
    "objectID": "01_VL_D.html#business-intelligence-2",
    "href": "01_VL_D.html#business-intelligence-2",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence",
    "text": "Business Intelligence\nBetriebliche Dimensionen\n\n\n\nBegriffsdimensionen von BI nach Schieder (2016).\n\n\n\n\nEine Personengruppe innerhalb der Organisation ist mit der Realisierung von BI-Prozessen vertraut.\nDie Generierung geschäftsrelevanter Informationen, Erkenntnisse und Wissen erfordert die Überführung fragmentierter Unternehmens- und Wettbewerbsdaten in handlungsgerichtetes Wissen. Hierbei liegt der Fokus auf dem Geschäftsprozess von der Datenerfassung hin zur Wissenskommunnikation.\nBezeichnet das Ergebnis eines Erkenntnissprozesses, beispielsweise ziel- und zweckorientiertes Wissen in Form von Berichten, Analysen und Prognosen für das Management.\nEine Sammlung von informationstechnischen Werkzeugen, Architekturen, Systemen und Technologien zur Aufbereitung und Bereitstellung reschäftsrelevanter Daten zum Zweck der Informationsgewinnung.\n\nIm Mittelpunkt dieser Vorlesung steht der BI-Prozess, beginnend mit der Datenerfassung und -bereitstellung im unternehmenseigenen Data Warehouse, über die Informationsentdeckung bzw. -generierung mit modellgestützten Analysemethoden, bis hin zur Kommunikation. Jeder Bestandteil des BI-Prozesses wird dabei um wichtige technische Aspekte ergänzt, bspw. Data Warehouse Architekturen, ausgewählten Analysemethoden und Einblicken in moderne BI-Dashboard-Tools. Ziel ist eine ganzheitliche Sicht auf den BI-Prozess im Unternehmenskontext."
  },
  {
    "objectID": "01_VL_D.html#data-science",
    "href": "01_VL_D.html#data-science",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nBegriffsabgrenzung\n\n\n\n\n\n\nDefinition\n\n\nData Science beschäftigt sich mit einer zweckorientierten Datenanalyse und der systematischen Generierung von Entscheidungshilfen und -grundlagen, um Wettbewerbsvorteile erzielen zu können. Der Schwerpunkt liegt dabei nicht auf den Daten selbst, sondern auf der Art und weise, wie diese verarbeitet und analysiert werden (siehe Gesellschaft für Informatik 2019).\n\n\n\n\n\nData Science ist ein vergleichsweise neues wissenschaftliches Feld, eine Kombination aus Statistik und Informatik, insbesondere Software Engineering\nDa es sich um ein junges Feld handelt sind Definitionen und die damit verbundenen Rollen im stetigen Wandel\n\n\n\nDieser Wandel geht so weit, dass die Rolle “Data Scientist” heute seltener auf Job-Portalen zu finden ist, als noch vor einigen Jahren. Stattdessen werden vermehrt spezialisierte Rollen wie “Data Engineer”, “Data Analyst” oder “Machine Learning Engineer” ausgeschrieben."
  },
  {
    "objectID": "01_VL_D.html#data-science-1",
    "href": "01_VL_D.html#data-science-1",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nSchwerpunkte\n\nAufgrund der potentiellen Breite des Felds erfolgt oft eine genauere Aufteilung in vier Kernbereiche:\n\n\n\nData Engineering: Methoden und Prozesse für die Speicherung, Haltung und Replikation von Daten\nData Analytics: Datenanalyse mit statistischen Methoden\nPredictive Modelling: Die Verwendung von statistischen Methoden zur Vorhersage\nMachine Learning: Algorithmen, die aus Daten lernen, Muster erkennen und hierauf aufbauend neue Situationen oder zukünftige Entwicklungen vorhersagen"
  },
  {
    "objectID": "01_VL_D.html#data-science-2",
    "href": "01_VL_D.html#data-science-2",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nReifegrade von Data Analytics\n\n\n\nQuelle: Milind Desai on Medium.com\n\n\n\n\nDescriptive Analytics: Beschreibende Analyse des Ist-Zustandes und der Vergangenheit. Im Mittelpunkt steht die Frage: Was ist passiert?\nDiagnostic Analytics: Analysiert die Zusammenhänge, die zum Ist-Zustand geführt haben und führt oft mehrere deskriptive Charakteristika zusammen: Warum ist der Status Quo eingetreten?\nPredictive Modelling: Ausgehend von einem detaillierten Verständnis des Status Quo wird eine Prognose für die Zukunft erstellt: Was wird passieren?\nPrescriptive Analytics: Dient der Identifizierung möglicher Handlungsoptionen auf Basis der Prognosen, entweder um eine schlechte Prognose abzuwenden oder die Realisierung einer guten Prognose zu unterstützen. Mit anderen Worten: Was muss getan werden, um die Zukunft zu unseren Gunsten zu beeinflussen"
  },
  {
    "objectID": "01_VL_D.html#data-science-3",
    "href": "01_VL_D.html#data-science-3",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nData Science, Data Analytics, Data Mining?\n\n\nDie Unterscheidung zwischen den Begriffen Data Analytics, Data Mining und Data Science ist nicht immer trennscharf\nData Mining ist meist definiert als der Prozess der Informationsextraktion aus Daten und ist ebenso wie Data Analytics eine Teilmenge von Data Science\nIn dieser Vorlesung dient Data Science als methodischer Baukasten, um den BI-Prozess mit modellgestützten Methoden anzureichern und Zusammenhänge sichtbar zu machen\nHierbei steht der Zweck der Modelle, nämlich die Entscheidungsunterstützung, im Vordergrund"
  },
  {
    "objectID": "01_VL_D.html#business-intelligence-und-data-science",
    "href": "01_VL_D.html#business-intelligence-und-data-science",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence und Data Science",
    "text": "Business Intelligence und Data Science\nZusammenführung der Begriffe und inhaltlicher Aufbau der Vorlesung\n\n\n\nBIA Gesamtansatz. Eigene Darstellung in Anlehnung an Baars und Kemper (2021).\n\n\n\nDie Abbildung illustriert den BIA-Ansatz als dreiteiligen Ordnungsrahmen, bestehend aus Datenbereitstellung, Informationsgenerierung und Informationsbereitstellung. Die Datenerfassung aus operativen und externen Systemen ist diesem Ordnungsrahmen hier vorgelagert. Das hieraus entstehende Modell entspricht der prozessualen BI-Dimension.\nGanz unten startenw ir mit zahlreichen operative und externen Quellsysteme, beispielsweise ERP-Systeme (häufig SAP), Produktdatenmanagement Systeme (PDM) oder Manufacturing Execution Systeme (MES).\nHinzu kommen häufig offene Daten wie Wetter- oder Konjunkturdaten und insbesondere im industriellen Kontext verstärkt Sensordaten aus internetfähigen Maschinen, sogenannte Internet of Things (IoT) Devices. Die strukturierte und systematische Integration dieser Daten mittels ETL Methoden (Extract, Transfer, Load), ist die erste Herausforderung jedes integrierten BIA-Systems.\nDie sogenannte Datenbereitstellung dient der konsistenten und strukturierten Speicherung und Persistierung aller relevanten Daten aus den oben genannten Quellsystemen. Hier gilt es verschiedene Konzepte näher zu beleuchten, insbesondere gängige Data Warehouse Konzepte, die meist aus sogenannten Data Marts und Core Data Warehouses bestehen und der themenbezogenen und integrierten Datenhaltung dienen. Je nach Anwendung wird das Datenmaterial meist voraggregiert. Zur Integration großvolumiger und schnell einlaufender Daten hat sich ergänzend das Konzept eines Data Lakes etabliert, in dem anders als im Data Warehouse Rohdaten ohne Aggregation abgelegt und verfügbar gemacht werden.\nDie Informationsgenerierung als zweite Schicht dient der Umwandlung der Rohdaten in entscheidungsfreundliche Formate, bspw. berichtsorientierte oder modellgestützte Analysen. Hier werden aus Daten erste Informationen generiert, auf Basis derer weitere Erkenntnisse über den Status Quo entstehen und mögliche Prognosen für die Zukunft erstellt werden können. Das Bindeglied zwischen Datenbereitstellung und Informationsgenerierung sind Systeme zur Datenabfrage und Exploration.\nDie Darstellung, Kanalisierung und Verbreitung von Informationen folgt in der dritten Schicht, der Informationsbereitstellung. Neben modernen Self-Service BI-Tools umfasst dies auch zielgruppenadäquate Präsentationen oder statische Berichte."
  },
  {
    "objectID": "01_VL_D.html#dispositive-und-operative-daten",
    "href": "01_VL_D.html#dispositive-und-operative-daten",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nOperative versus dispositive Aufgaben\n\n\nAnders als die anfänglichen MSS unterstützen moderne BI-Systeme sowohl operative, als auch dispositive Aufgaben\nDispositive Aufgaben sind Leitungs- und Lenkungstätigkeiten im betrieblichen Ablauf\nOperative Aufgaben umfassen die Leistungserstellung oder -verwertung\nAn beide Aufgabenfelder gelten unterschiedliche Anforderungen, die in Daten und Systemen abgebildet werden müssen"
  },
  {
    "objectID": "01_VL_D.html#dispositive-und-operative-daten-1",
    "href": "01_VL_D.html#dispositive-und-operative-daten-1",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nOperative versus dispositive Daten\n\n\n\n\nDispositive Daten\n\nUnterstützen Leitungs- und Lenkungstätigkeiten im betrieblichen Ablauf\nHäufig verdichtet, transformiert und themenbezogen aufbereitet und mit Historie angereichert\n\n\nOperative Daten\n\nDienen der Abwicklung von Geschäftsprozessen und werden im Rahmen von Transaktionen1 erzeugt\nSehr granular und mit hoher Änderungsrate\nBeispiele sind Bestellungen, Aufträge und Lagerbestände oder Stammdaten\n\n\n\n\n\nAtomare und logisch untrennbare Datenbankvorgänge"
  },
  {
    "objectID": "01_VL_D.html#dispositive-und-operative-daten-2",
    "href": "01_VL_D.html#dispositive-und-operative-daten-2",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nOperative versus dispositive Daten\n\n\nCharakteristika operativer und entscheidungsorientierter Daten im Vergleich. In Anlehnung an Baars und Kemper (2021)\n\n\n\n\n\n\n\n\nOperative Daten\nEntscheidungsorientierte Daten\n\n\n\n\nZiel\nAbwicklung der Geschäftsprozesse\nInformationen für Entscheidungen\n\n\nAusrichtung\nDetailliert und granular\nMeist verdichtet und transformiert mit Metadaten\n\n\nZeitbezug\nAktualität steht im Vordergrund, Zeitpunkt der Transaktion, keine Historisierung\nAktualität variiert mit der Aufgabe, Historienbetrachtung ist möglich\n\n\nModellierung\nKeine Altbestände\nSachgebiets- und themenbezogen orientiert und anwendungstauglich\n\n\nZustand\nHäufig redundant und inkonsistent zwischen Systemen\nKonsistent modelliert, Redundanz bewusst\n\n\nUpdate\nLaufend, Real-time\nErgänzend als Fortschreibung\n\n\nQueries\nStrukturiert, standardisiert und meistens statisch\nAd-hoc und dynamisch für wechselnde Fragestellungen sowie Standardberichte"
  },
  {
    "objectID": "01_VL_D.html#dispositive-und-operative-daten-3",
    "href": "01_VL_D.html#dispositive-und-operative-daten-3",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nÜberführung von Daten in Information\n\n\n\nHauptziel dieser Vorlesung ist die Überführung von operationalen Daten in entscheidungsrelevante Informationen\nDies hat zwei Hauptaspekte:\n\nBlock 1-4: Technische Infrastruktur und Architektur\nBlock 5-9: Methodische Konzepte wie modellorientierte Analysen\n\n\n\n\n\n\n\n\nBlock\nThema\n\n\n\n\n1\nOrganisation, Einleitung\n\n\n2\nDatenbereitstellung: Data Warehousing\n\n\n3\nDatentransformation\n\n\n4\nBig Data und Data Lake\n\n\n5\nInformationsgenerierung: Berichtsorientierte Analysen\n\n\n6\nAdvanced und Predictive Analytics: Grundlagen\n\n\n7\nAdvanced und Predictive Analytics: Klassifikation\n\n\n8\nAdvanced und Predictive Analytics: Klassifikation\n\n\n9\nInformationsbereitstellung: Visualisierungstechniken"
  },
  {
    "objectID": "01_VL_D.html#apache-superset",
    "href": "01_VL_D.html#apache-superset",
    "title": "Business Intelligence & Data Science",
    "section": "Apache Superset",
    "text": "Apache Superset\nErster Login und Überblick\n\n\n\nApache Superset ist ein Open Source BI-Tool, das über die Vorlesung hinweg neben R als zentrales Tool dient\nDas Tool ist in einem sogenannten Kubernetes Cluster in der Google Cloud gehosted und kann über folgenden Link erreicht werden:\n\nhttp://34.95.70.95/login/\n\nDie Verbindung ist (aktuell noch) nicht https verschlüsselt, daher wird ein Warnhinweis erscheinen, der sich je nach Browser unterschiedlich umgehen lässt\nDie Anmeldung erfolgt mit den Zugangsdaten, die auf StudIP veröffentlicht sind\nDie Superset Instanz bleibt bis zur letzten Vorlesung online, bis dahin erstellte Dashboards und Grafiken werden als Export auf StudIP bereitgestellt"
  },
  {
    "objectID": "01_VL_D.html#apache-superset-1",
    "href": "01_VL_D.html#apache-superset-1",
    "title": "Business Intelligence & Data Science",
    "section": "Apache Superset",
    "text": "Apache Superset\nTerminologie\n\n\nDatabase:\n\nBackend-Datenbank, in der die Rohdaten liegen, das Pendant zu einem Data Warehouse\nIn unserem Fall Google BigQuery, aber auch andere Datenbanken wie MySQL, PostgreSQL oder SQLite sind möglich\nAuch der Upload von Excel und CSV Dateien ist möglich\n\nDataset:\n\nEinzelne Tabellen in der Datenbank, die als Grundlage für Analysen und Visualisierungen dienen\nBasieren auf Rohdaten, die für die Visualisierung verarbeitet werden\nPhysische Datasets “leben” auf der Backend-Datenbank, virtuelle Datasets sind direkt in Superset generiert und gespeichert"
  },
  {
    "objectID": "01_VL_D.html#apache-superset-2",
    "href": "01_VL_D.html#apache-superset-2",
    "title": "Business Intelligence & Data Science",
    "section": "Apache Superset",
    "text": "Apache Superset\nTerminologie\n\n\nDashboard:\n\nEine Sammlung von Visualisierungen, die in einem gemeinsamen Kontext dargestellt werden\nEin Dashboard kann mehrere Visualisierungen enthalten, die auf unterschiedlichen Datasets basieren\nDie Visualisierungen können über globale Filter gefiltert werden\n\nChart:\n\nEigenständige Visualisierung eines Datasets, die eigenständig oder in einem Dashboard dargestellt werden kann\nEs gibt eine Vielzahl von Chart-Typen, die in Superset dargestellt werden können\nPreset.io gibt eine Übersicht über die gängigsten Chart-Typen"
  },
  {
    "objectID": "01_VL_D.html#apache-superset-3",
    "href": "01_VL_D.html#apache-superset-3",
    "title": "Business Intelligence & Data Science",
    "section": "Apache Superset",
    "text": "Apache Superset\nTerminologie\n\n\nDimensions:\n\nDimensionen sind die Kategorien, nach denen Daten gruppiert\nIdealerweise kategoriale Variablen, die nicht aggregiert werden\nWenn die Daten eine Zeitdimension enthalten (erkennbar am Uhren-Symbol) ist eine spezielle Time Dimension verfügbar\nBei korrekter Pflege der Zeitvariable lässt sich direkt auf Tages-, Wochen-, Monats- und Jahreswerte aggregieren mittels Time Grain\n\nMetrics\n\nQuantitative Variablen, die sich mit Funktionen aggregieren lassen\nBeispielfunktionen sind Summen, Durchschnitte, Min und Max oder Counts\nBesonderheit: Viele BI-Tools erstellen per Default eine Count-Metrik, die Datenpunkte pro Dimension zählt"
  },
  {
    "objectID": "01_VL_D.html#warmup",
    "href": "01_VL_D.html#warmup",
    "title": "Business Intelligence & Data Science",
    "section": "Warmup",
    "text": "Warmup\nDatenexploration in Superset\n\nWir starten mit einer kurzen Datenexploration in Superset mit dem Dataset “Warmup”\nHierzu gehen wir auf der Startseite auf Charts und wählen oben rechts +Chart aus\nNun sind 2 Schritte notwendig:\n\nAuswahl des Datasets\n\nHier wählen wir “Warmup” aus\n\nAuswahl des Chart-Typs\n\nEin guter Startpunkt für die explorative Analyse ist eine Tabelle, also wählen wir Table"
  },
  {
    "objectID": "01_VL_D.html#warmup-1",
    "href": "01_VL_D.html#warmup-1",
    "title": "Business Intelligence & Data Science",
    "section": "Warmup",
    "text": "Warmup\nDatenexploration in Superset"
  },
  {
    "objectID": "01_VL_D.html#warmup-2",
    "href": "01_VL_D.html#warmup-2",
    "title": "Business Intelligence & Data Science",
    "section": "Warmup",
    "text": "Warmup\nDatenexploration in Superset"
  },
  {
    "objectID": "01_VL_D.html#warmup-3",
    "href": "01_VL_D.html#warmup-3",
    "title": "Business Intelligence & Data Science",
    "section": "Warmup",
    "text": "Warmup\nDatenexploration in Superset\n\nFragen:\n\nWie viele Zeilen hat der Datensatz?\nWelche Genres und Artists gibt es?\nWie viele Songs gibt es pro Genre?\nWas ist die durchschnittliche Beliebtheit pro Artist?\nWann ist das aktuellste (älteste) Album erschienen?"
  },
  {
    "objectID": "01_VL_D.html#quellen",
    "href": "01_VL_D.html#quellen",
    "title": "Business Intelligence & Data Science",
    "section": "Quellen",
    "text": "Quellen\n\n\nBusiness Intelligence & Data Science, SoSe 2024\n\n\n\nBaars, Henning, und Hans-Georg Kemper. 2021. Business Intelligence & Analytics: Grundlagen und praktische Anwendungen: Ansätze der IT-basierten Entscheidungsunterstützung. 4., überarbeitete und erweiterte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Vieweg.\n\n\nGesellschaft für Informatik. 2019. „Data Science: Lern- und Ausbildungsinhalte“. Gesellschaft für Informatik.\n\n\nSchieder, Christian. 2016. „Historische Fragmente einer Integrationsdisziplin – Beitrag zur Konstruktgeschichte der Business Intelligence“. In Analytische Informationssysteme, herausgegeben von Peter Gluchowski und Peter Chamoni, 13–32. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-47763-2_2.\n\n\nSharma, Vinod, Jeanne Poulose, und Chandan Maheshkar. 2023. „Analytics Enabled Decision Making ‚Tracing the Journey from Data to Decisions‘“. In Analytics Enabled Decision Making, herausgegeben von Vinod Sharma, Chandan Maheshkar, und Jeanne Poulose, 1–22. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-19-9658-0_1.\n\n\nWinter, Robert. 2016. „Analytische Informationssysteme aus Managementsicht: lokale Entscheidungsunterstützung vs. unternehmensweite Informations-Infrastruktur“. In Analytische Informationssysteme, herausgegeben von Peter Gluchowski und Peter Chamoni, 67–95. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-47763-2_5."
  },
  {
    "objectID": "01_VL.html#der-plan-für-heute",
    "href": "01_VL.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung 1\n\n\nVorstellung & kurzes Kennenlern-Quiz\nOrganisatorisches\nEinleitung:\n\nWas sind Business Intelligence & Data Science?\nWas sind operative und dispositive Daten?\nWie werden aus operativen Daten entscheidungsrelevante Informationen?\n\n\n\n\n\nWir starten mit einer kurzen Vorstellung, in der ich mich kurz vorstelle und anschließend gibt es ein kurzes Quiz, das einerseits Quizzes als Tool einführt, mit dem wir künftig die Doppelblöcke eröffnet und mir andererseits die Gelegenheit gibt, den Wissenstand abzuklopfn\nDann folgt ein Stresstest für unser BI-Tool Apache Superset, das wir künftig für die Visualisierung von Daten nutzen werden, indem wir uns alle gleichzeitig einloggen und testen, ob das System der Last standhält\nHiernach folgen ein paar organisatorische Hinweise, bevor wir in die inhaltliche Einführung starten:\n\nWas ist das eigentlich, Business Intelligence und Data Science?\nWie werden Informationen aus operativen Daten gewonnen?"
  },
  {
    "objectID": "01_VL.html#vorstellung",
    "href": "01_VL.html#vorstellung",
    "title": "Business Intelligence & Data Science",
    "section": "Vorstellung",
    "text": "Vorstellung\nKennenlern-Quiz\n\n\nDas Kennenlern-Quiz umfasst Fragen zu Vorkenntnissen rund um BI-Software und R, um ein Gefühl für den Wissensstand zu bekommen.\nAußerdem gibt es wichtige Fachfragen rund um BI und Data Science.\nDie Gewinnerin/Der Gewinner erhält einen überragenden Preis\nAls Plattform dient Quizziz.com, es ist keine Registrierung notwendig, Verwendung über Smartphone und Laptop möglich\nKünftig starten wir einen Doppelblock mit einem Quiz zum vorangeganenen Block mit einem kleinen Preis für den Tagessieg"
  },
  {
    "objectID": "01_VL.html#warum-bi-und-data-science",
    "href": "01_VL.html#warum-bi-und-data-science",
    "title": "Business Intelligence & Data Science",
    "section": "Warum BI und Data Science?",
    "text": "Warum BI und Data Science?\nEntscheidende Skills für die berufliche Zukunft\n\n\n\nQuelle: McKinsey\n\n\n\n\nDie Grafik zeigt die sogenannten Delta Skills nach McKinsey, das sind jene Fähigkeiten, die einen Unterschied machen werden, um in der Arbeitswelt der Zukunft erfolgreich zu sein.\nDie Kategorien sind: Kognitiv, Interpersonell, Selbstführung und Digital\nUnser FOkus ist die Kategorie Digital, die sich wiederum in die Bereiche Digital Fluency, Software Nutzung und Entwicklung sowie Verständnis digitaler Systeme aufteilt.\nWas ist digital Fluency? Es ist die Fähigkeit, digitale Tools und Technologien zu nutzen und hier Digital Learning und Collaboration besonders wichtig.\nSoftware Nutzung und Entwicklung umfasst insbesondere Programming und Datenanalyse, insbesondere den zweiten Punkt werden wir sehr ausführlich im Methodenteil zu Data Science behandeln.\nZiel ist hier nicht, in wenigen Blöcken eine vollwertige Ausbildung in diesem Bereich zu ersetzen, sondern vielmehr das Big Picture zu vermitteln, um im Unternehmen als guter Sparringspartner für Data Science Themen und Projekte zu fungieren.\nProgramming wird eher nebenbei mit einfließen\nEin entscheidender Punkt ist unten rechts die Data Literacy. Das umfasst die Fähigkeit, Daten zu lesen, zu interpretieren und zu kommunizieren. Das ist ein zentraler Punkt, den wir in dieser Vorlesung adressieren werden. Meines Erachtens der größte Knackpunkt im Unternehmensumfeld, da hier die größte Lücke zwischen den Fachbereichen und der IT besteht."
  },
  {
    "objectID": "01_VL.html#warum-bi-und-data-science-1",
    "href": "01_VL.html#warum-bi-und-data-science-1",
    "title": "Business Intelligence & Data Science",
    "section": "Warum BI und Data Science?",
    "text": "Warum BI und Data Science?\nTechnologische Kompetenzen\n\n\n\nLink zur Quelle\n\n\n\n\nDie Grafik zeigt die Ergebnisse einer Studie des Stifterverbands, die sich mit den zukünftigen Anforderungen an die Arbeitswelt befasst.\nEs handelt sich hier um eine Umfrage und die Grafik gibt den Anteil der teilnehmenden an, welche die gegeben Aspekte jetzt und in 5 Jahren als wichtig erachten.\nFür uns wichtig sind IT-Architektur und Data Analytics & KI\nDie Vorlesung wird einige Architektur-Komponenten umfassen, nämlich den Aufbau einer BI-Architektur und eine Einbettung ins Unternehmen allgemein\nData Analytics und KI umfasst die Methoden, die wir in der zweiten Hälfte der Vorlesung behandeln werden, wobei der Fokus weniger auf KI liegt und mehr auf den Data Science Methoden, die vielen KI-Technologien zu Grunde liegen"
  },
  {
    "objectID": "01_VL.html#kursaufbau",
    "href": "01_VL.html#kursaufbau",
    "title": "Business Intelligence & Data Science",
    "section": "Kursaufbau",
    "text": "Kursaufbau\nZeitplan Gruppe C\n\n\n\n\n\nBlock\nGruppe C\nThema\n\n\n\n\n1\n13.03.2024:13:00 – 14:30\nOrganisation, Einleitung\n\n\n2\n13.03.2024:14:45 – 16:15\nDatenbereitstellung: Data Warehousing\n\n\n3\n22.03.2024:09:00 – 10:30\nDatentransformation\n\n\n4\n22.03.2024:10:45 – 12:15\nBig Data und Data Lake\n\n\n5\n28.03.2024:09:00 – 10:30\nInformationsgenerierung: Berichtsorientierte Analysen\n\n\n6\n28.03.2024:10:45 – 12:15\nAdvanced und Predictive Analytics: Grundlagen\n\n\n7\n16.04.2024:13:00 – 14:30\nAdvanced und Predictive Analytics: Klassifikation\n\n\n8\n16.04.2024:14:45 – 16:15\nAdvanced und Predictive Analytics: Klassifikation\n\n\n9\n30.04.2024:13:00 – 14:30\nInformationsbereitstellung: Visualisierungstechniken\n\n\n10\n30.04.2024:14:45 – 16:15\nWild Card: Wunschthema oder Restinhalte und Q\\&A\n\n\n-\n13.05.2024:13:00 – 14:30\nKlausur (60 Minuten)"
  },
  {
    "objectID": "01_VL.html#kursaufbau-1",
    "href": "01_VL.html#kursaufbau-1",
    "title": "Business Intelligence & Data Science",
    "section": "Kursaufbau",
    "text": "Kursaufbau\nZeitplan Gruppe D\n\n\n\n\n\nBlock\nGruppe D\nThema\n\n\n\n\n1\n21.03.2024:09:00 – 10:30\nOrganisation, Einleitung\n\n\n2\n21.03.2024:10:45 – 12:15\nDatenbereitstellung: Data Warehousing\n\n\n3\n28.03.2024:13:00 – 14:30\nDatentransformation\n\n\n4\n28.03.2024:14:45 – 16:15\nBig Data und Data Lake\n\n\n5\n02.04.2024:13:00 – 14:30\nInformationsgenerierung: Berichtsorientierte Analysen\n\n\n6\n02.04.2024:14:45 – 16:15\nAdvanced und Predictive Analytics: Grundlagen\n\n\n7\n15.04.2024:13:00 – 14:30\nAdvanced und Predictive Analytics: Klassifikation\n\n\n8\n15.04.2024:14:45 – 16:15\nAdvanced und Predictive Analytics: Klassifikation\n\n\n9\n02.05.2024:13:00 – 14:30\nInformationsbereitstellung: Visualisierungstechniken\n\n\n10\n02.05.2024:14:45 – 16:15\nWild Card: Wunschthema oder Restinhalte und Q\\&A\n\n\n-\n13.05.2024:13:00 – 14:30\nKlausur (60 Minuten)"
  },
  {
    "objectID": "01_VL.html#kursmaterialen",
    "href": "01_VL.html#kursmaterialen",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialen",
    "text": "Kursmaterialen\nKurs-Website\n\nAlle Kursinhalte sind auf der Kurs-Website verfügbar:\n\nhttps://sebschroen.github.io/bi_and_ds-lecture_notes/\n\n\n\n\nAktuell passwortgeschützt aufgrund Nutzung Copyright-geschützter Materialien, daher nur Nutzung in diesem Personenkreis\n3 gefundene und gemeldete Typos (E-Mail, StudIP) = 1 Packung Bahlsen-Kekse nach Wahl\nTipp: Bookmark des Links nach Passworteingabe erübrigt künftige Eingabe des Passworts\n\n\n\n\nPasswort anschreiben\nEinfach zusammen durchklicken und kurz Zeit zur Orientierung geben, Trick zum Bookmark zeigen"
  },
  {
    "objectID": "01_VL.html#kursmaterialen-1",
    "href": "01_VL.html#kursmaterialen-1",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialen",
    "text": "Kursmaterialen\nFolien\n\n\nFolien sind auf der Startseite der Kurs-Website verlinkt\nDarstellung ist für den Browser (Chrome, Safari und Firefox) optimiert, um interaktive Elemente darzustellen\nIm Burger-Menü oben rechts lässt sich zu jeder Zeit auch eine PDF Version zum Ausdruck in Papierform oder für Notizen erstellen:\n\nTools -&gt; PDF Export Mode -&gt; Strg + P (Cmd + P) -&gt; Druck als PDF\n\nDie Folien werden rechtzeitig vor der Vorlesung als PDF auf StudIP hochgeladen\nInteraktive Elemente werden separat verlinkt.\n\n\n\n\nDie Folien sind im Ablaufplan auf der Startseite in aktueller Fassung verlinkt und lassen sich auf mehreren Wegen darstellen.\n\n\nKonzipiert sind die Folien für die Darstellung im Browser, um interaktive Elemente darzustellen.\nIm Menü oben rechts lässt sich zu jeder Zeit auch eine PDF Version zum Ausdrucken in Papierform erstellen oder zur Darstellung auf Endgeräten, auf denen Sie Notizen machen möchten.\nAm Ende jeder Vorlesung wird die finale Fassung der Folien auf StudIP im PDF Format hochgeladen.\nDie HTML Fassung bleibt verfügbar."
  },
  {
    "objectID": "01_VL.html#kursmaterialen-2",
    "href": "01_VL.html#kursmaterialen-2",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialen",
    "text": "Kursmaterialen\nPDF-Skript\n\nNeben der HTML-Version ist auch ein PDF-Skript verfügbar und kann auf der Startseite heruntergeladen werden\nDie PDF-Version entspricht inhaltlich immer der Website\nDie Darstellung ist für HTML optimiert und kann für Artefakte beim PDF Rendering sorgen, erleichtert aber das Ausdrucken\n\n\n\nDie PDF-Version zum Skript ist auf der Startseite der Website verlinkt und entspricht inhaltlich immer der Website.\nDie Darstellung ist für html optimiert und kann für Artefakte beim PDF Rendering sorgen, erleichtert aber das Ausdrucken"
  },
  {
    "objectID": "01_VL.html#kursmaterialien",
    "href": "01_VL.html#kursmaterialien",
    "title": "Business Intelligence & Data Science",
    "section": "Kursmaterialien",
    "text": "Kursmaterialien\nErgänzende Literatur\n\n\n\nAlle klausurrelevanten Inhalte lassen sich auf der Kurs-Website finden und nachlesen, zusätzliche Literatur ist nicht notwendig\nDer Aufbau des Kurses richtet sich nach dem Lehrbuch Business Intelligence & Analytics - Grundlagen und praktische Anwendungen, 4. Auflage von Henning Baars und Hans-Georg Kemper\nDas Buch ist über die Bibliothek der Leibniz FH als E-Book verfügbar\nBlock 1 - 5 entstammen größtenteils in Baars und Kemper (2021)\nMethodische Aspekte rund um Predictive Analytics entstammen größtenteils dem frei verfügbaren Introduction to Statistical Learning, 2. Auflage von Gareth James, Daniela Witten, Trevor Hastie und Robert Tibshirani\nDie Quellen zu jeder Vorlesung sind jeweils auf der letzten Folien angegeben."
  },
  {
    "objectID": "01_VL.html#business-intelligence",
    "href": "01_VL.html#business-intelligence",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence",
    "text": "Business Intelligence\nBegriffsabgrenzung\n\n\n\n\n\n\nDefinition\n\n\nBusiness Intelligence (BI) ist eine Reihe von Architekturen und Technologien, die Rohdaten in sinnvolle und nutzbare, entscheidungsrelevante Informationen umwandeln. Es ermöglicht Anwendenden, informierte Entscheidungen auf der Grundlage von Daten zu treffen, die ein Unternehmen gegenüber seinen Wettbewerbern in Vorteil bringen können (siehe Forrester.com).\n\n\n\n\n\nAbgeleitet vom Intelligence-Begriff in der militärischen Informationsverarbeitung Großbritanniens im 2. Weltkrieg:\n\nDie richtigen Informationen zur richtigen Zeit an die richtigen Personen.\n\nFrühe kommerzielle Ansätze in den 60er Jahren im Zuge der Entwicklung relationaler Datenbanken."
  },
  {
    "objectID": "01_VL.html#business-intelligence-1",
    "href": "01_VL.html#business-intelligence-1",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence",
    "text": "Business Intelligence\nBegriffsabgrenzung\n\n\nZunächst Fokus auf Management Support Systeme (MSS) und daher eher auf oberste Ebenen zugeschnitten\nDer Begriff Business Intelligence (BI) wurde in den 1990ern geprägt\nHeute wird BI laut Gartner Group charakterisiert durch:\n\nBreite Verfügbarkeit von BI Tools auf allen Ebenen des Unternehmens\nGeschäftsentscheidung auf Basis aktueller Informationen und Daten und nicht auf Intuition\nUmfangreiche Analyse- und Reportingmöglichkeiten mit Self-Service Tools für Fachbereiche"
  },
  {
    "objectID": "01_VL.html#business-intelligence-2",
    "href": "01_VL.html#business-intelligence-2",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence",
    "text": "Business Intelligence\nBetriebliche Dimensionen\n\n\n\nBegriffsdimensionen von BI nach Schieder (2016).\n\n\n\n\nEine Personengruppe innerhalb der Organisation ist mit der Realisierung von BI-Prozessen vertraut.\nDie Generierung geschäftsrelevanter Informationen, Erkenntnisse und Wissen erfordert die Überführung fragmentierter Unternehmens- und Wettbewerbsdaten in handlungsgerichtetes Wissen. Hierbei liegt der Fokus auf dem Geschäftsprozess von der Datenerfassung hin zur Wissenskommunnikation.\nBezeichnet das Ergebnis eines Erkenntnissprozesses, beispielsweise ziel- und zweckorientiertes Wissen in Form von Berichten, Analysen und Prognosen für das Management.\nEine Sammlung von informationstechnischen Werkzeugen, Architekturen, Systemen und Technologien zur Aufbereitung und Bereitstellung reschäftsrelevanter Daten zum Zweck der Informationsgewinnung.\n\nIm Mittelpunkt dieser Vorlesung steht der BI-Prozess, beginnend mit der Datenerfassung und -bereitstellung im unternehmenseigenen Data Warehouse, über die Informationsentdeckung bzw. -generierung mit modellgestützten Analysemethoden, bis hin zur Kommunikation. Jeder Bestandteil des BI-Prozesses wird dabei um wichtige technische Aspekte ergänzt, bspw. Data Warehouse Architekturen, ausgewählten Analysemethoden und Einblicken in moderne BI-Dashboard-Tools. Ziel ist eine ganzheitliche Sicht auf den BI-Prozess im Unternehmenskontext."
  },
  {
    "objectID": "01_VL.html#data-science",
    "href": "01_VL.html#data-science",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nBegriffsabgrenzung\n\n\n\n\n\n\nDefinition\n\n\nData Science beschäftigt sich mit einer zweckorientierten Datenanalyse und der systematischen Generierung von Entscheidungshilfen und -grundlagen, um Wettbewerbsvorteile erzielen zu können. Der Schwerpunkt liegt dabei nicht auf den Daten selbst, sondern auf der Art und weise, wie diese verarbeitet und analysiert werden (siehe Gesellschaft für Informatik 2019).\n\n\n\n\n\nData Science ist ein vergleichsweise neues wissenschaftliches Feld, eine Kombination aus Statistik und Informatik, insbesondere Software Engineering\nDa es sich um ein junges Feld handelt sind Definitionen und die damit verbundenen Rollen im stetigen Wandel\n\n\n\nDieser Wandel geht so weit, dass die Rolle “Data Scientist” heute seltener auf Job-Portalen zu finden ist, als noch vor einigen Jahren. Stattdessen werden vermehrt spezialisierte Rollen wie “Data Engineer”, “Data Analyst” oder “Machine Learning Engineer” ausgeschrieben."
  },
  {
    "objectID": "01_VL.html#data-science-1",
    "href": "01_VL.html#data-science-1",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nSchwerpunkte\n\nAufgrund der potentiellen Breite des Felds erfolgt oft eine genauere Aufteilung in vier Kernbereiche:\n\n\n\nData Engineering: Methoden und Prozesse für die Speicherung, Haltung und Replikation von Daten\nData Analytics: Datenanalyse mit statistischen Methoden\nPredictive Modelling: Die Verwendung von statistischen Methoden zur Vorhersage\nMachine Learning: Algorithmen, die aus Daten lernen, Muster erkennen und hierauf aufbauend neue Situationen oder zukünftige Entwicklungen vorhersagen"
  },
  {
    "objectID": "01_VL.html#data-science-2",
    "href": "01_VL.html#data-science-2",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nReifegrade von Data Analytics\n\n\n\nQuelle: Milind Desai on Medium.com\n\n\n\n\nDescriptive Analytics: Beschreibende Analyse des Ist-Zustandes und der Vergangenheit. Im Mittelpunkt steht die Frage: Was ist passiert?\nDiagnostic Analytics: Analysiert die Zusammenhänge, die zum Ist-Zustand geführt haben und führt oft mehrere deskriptive Charakteristika zusammen: Warum ist der Status Quo eingetreten?\nPredictive Modelling: Ausgehend von einem detaillierten Verständnis des Status Quo wird eine Prognose für die Zukunft erstellt: Was wird passieren?\nPrescriptive Analytics: Dient der Identifizierung möglicher Handlungsoptionen auf Basis der Prognosen, entweder um eine schlechte Prognose abzuwenden oder die Realisierung einer guten Prognose zu unterstützen. Mit anderen Worten: Was muss getan werden, um die Zukunft zu unseren Gunsten zu beeinflussen"
  },
  {
    "objectID": "01_VL.html#data-science-3",
    "href": "01_VL.html#data-science-3",
    "title": "Business Intelligence & Data Science",
    "section": "Data Science",
    "text": "Data Science\nData Science, Data Analytics, Data Mining?\n\n\nDie Unterscheidung zwischen den Begriffen Data Analytics, Data Mining und Data Science ist nicht immer trennscharf\nData Mining ist meist definiert als der Prozess der Informationsextraktion aus Daten und ist ebenso wie Data Analytics eine Teilmenge von Data Science\nIn dieser Vorlesung dient Data Science als methodischer Baukasten, um den BI-Prozess mit modellgestützten Methoden anzureichern und Zusammenhänge sichtbar zu machen\nHierbei steht der Zweck der Modelle, nämlich die Entscheidungsunterstützung, im Vordergrund"
  },
  {
    "objectID": "01_VL.html#business-intelligence-und-data-science",
    "href": "01_VL.html#business-intelligence-und-data-science",
    "title": "Business Intelligence & Data Science",
    "section": "Business Intelligence und Data Science",
    "text": "Business Intelligence und Data Science\nZusammenführung der Begriffe und inhaltlicher Aufbau der Vorlesung\n\n\n\nBIA Gesamtansatz. Eigene Darstellung in Anlehnung an Baars und Kemper (2021).\n\n\n\nDie Abbildung illustriert den BIA-Ansatz als dreiteiligen Ordnungsrahmen, bestehend aus Datenbereitstellung, Informationsgenerierung und Informationsbereitstellung. Die Datenerfassung aus operativen und externen Systemen ist diesem Ordnungsrahmen hier vorgelagert. Das hieraus entstehende Modell entspricht der prozessualen BI-Dimension.\nGanz unten startenw ir mit zahlreichen operative und externen Quellsysteme, beispielsweise ERP-Systeme (häufig SAP), Produktdatenmanagement Systeme (PDM) oder Manufacturing Execution Systeme (MES).\nHinzu kommen häufig offene Daten wie Wetter- oder Konjunkturdaten und insbesondere im industriellen Kontext verstärkt Sensordaten aus internetfähigen Maschinen, sogenannte Internet of Things (IoT) Devices. Die strukturierte und systematische Integration dieser Daten mittels ETL Methoden (Extract, Transfer, Load), ist die erste Herausforderung jedes integrierten BIA-Systems.\nDie sogenannte Datenbereitstellung dient der konsistenten und strukturierten Speicherung und Persistierung aller relevanten Daten aus den oben genannten Quellsystemen. Hier gilt es verschiedene Konzepte näher zu beleuchten, insbesondere gängige Data Warehouse Konzepte, die meist aus sogenannten Data Marts und Core Data Warehouses bestehen und der themenbezogenen und integrierten Datenhaltung dienen. Je nach Anwendung wird das Datenmaterial meist voraggregiert. Zur Integration großvolumiger und schnell einlaufender Daten hat sich ergänzend das Konzept eines Data Lakes etabliert, in dem anders als im Data Warehouse Rohdaten ohne Aggregation abgelegt und verfügbar gemacht werden.\nDie Informationsgenerierung als zweite Schicht dient der Umwandlung der Rohdaten in entscheidungsfreundliche Formate, bspw. berichtsorientierte oder modellgestützte Analysen. Hier werden aus Daten erste Informationen generiert, auf Basis derer weitere Erkenntnisse über den Status Quo entstehen und mögliche Prognosen für die Zukunft erstellt werden können. Das Bindeglied zwischen Datenbereitstellung und Informationsgenerierung sind Systeme zur Datenabfrage und Exploration.\nDie Darstellung, Kanalisierung und Verbreitung von Informationen folgt in der dritten Schicht, der Informationsbereitstellung. Neben modernen Self-Service BI-Tools umfasst dies auch zielgruppenadäquate Präsentationen oder statische Berichte."
  },
  {
    "objectID": "01_VL.html#dispositive-und-operative-daten",
    "href": "01_VL.html#dispositive-und-operative-daten",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nOperative versus dispositive Aufgaben\n\n\nAnders als die anfänglichen MSS unterstützen moderne BI-Systeme sowohl operative, als auch dispositive Aufgaben\nDispositive Aufgaben sind Leitungs- und Lenkungstätigkeiten im betrieblichen Ablauf\nOperative Aufgaben umfassen die Leistungserstellung oder -verwertung\nAn beide Aufgabenfelder gelten unterschiedliche Anforderungen, die in Daten und Systemen abgebildet werden müssen"
  },
  {
    "objectID": "01_VL.html#dispositive-und-operative-daten-1",
    "href": "01_VL.html#dispositive-und-operative-daten-1",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nOperative versus dispositive Daten\n\n\n\n\nDispositive Daten\n\nUnterstützen Leitungs- und Lenkungstätigkeiten im betrieblichen Ablauf\nHäufig verdichtet, transformiert und themenbezogen aufbereitet und mit Historie angereichert\n\n\nOperative Daten\n\nDienen der Abwicklung von Geschäftsprozessen und werden im Rahmen von Transaktionen1 erzeugt\nSehr granular und mit hoher Änderungsrate\nBeispiele sind Bestellungen, Aufträge und Lagerbestände oder Stammdaten\n\n\n\n\n\nAtomare und logisch untrennbare Datenbankvorgänge"
  },
  {
    "objectID": "01_VL.html#dispositive-und-operative-daten-2",
    "href": "01_VL.html#dispositive-und-operative-daten-2",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nOperative versus dispositive Daten\n\n\nCharakteristika operativer und entscheidungsorientierter Daten im Vergleich. In Anlehnung an Baars und Kemper (2021)\n\n\n\n\n\n\n\n\nOperative Daten\nEntscheidungsorientierte Daten\n\n\n\n\nZiel\nAbwicklung der Geschäftsprozesse\nInformationen für Entscheidungen\n\n\nAusrichtung\nDetailliert und granular\nMeist verdichtet und transformiert mit Metadaten\n\n\nZeitbezug\nAktualität steht im Vordergrund, Zeitpunkt der Transaktion, keine Historisierung\nAktualität variiert mit der Aufgabe, Historienbetrachtung ist möglich\n\n\nModellierung\nKeine Altbestände\nSachgebiets- und themenbezogen orientiert und anwendungstauglich\n\n\nZustand\nHäufig redundant und inkonsistent zwischen Systemen\nKonsistent modelliert, Redundanz bewusst\n\n\nUpdate\nLaufend, Real-time\nErgänzend als Fortschreibung\n\n\nQueries\nStrukturiert, standardisiert und meistens statisch\nAd-hoc und dynamisch für wechselnde Fragestellungen sowie Standardberichte"
  },
  {
    "objectID": "01_VL.html#dispositive-und-operative-daten-3",
    "href": "01_VL.html#dispositive-und-operative-daten-3",
    "title": "Business Intelligence & Data Science",
    "section": "Dispositive und operative Daten",
    "text": "Dispositive und operative Daten\nÜberführung von Daten in Information\n\n\n\nHauptziel dieser Vorlesung ist die Überführung von operationalen Daten in entscheidungsrelevante Informationen\nDies hat zwei Hauptaspekte:\n\nBlock 1-4: Technische Infrastruktur und Architektur\nBlock 5-9: Methodische Konzepte wie modellorientierte Analysen\n\n\n\n\n\n\n\n\nBlock\nThema\n\n\n\n\n1\nOrganisation, Einleitung\n\n\n2\nDatenbereitstellung: Data Warehousing\n\n\n3\nDatentransformation\n\n\n4\nBig Data und Data Lake\n\n\n5\nInformationsgenerierung: Berichtsorientierte Analysen\n\n\n6\nAdvanced und Predictive Analytics: Grundlagen\n\n\n7\nAdvanced und Predictive Analytics: Klassifikation\n\n\n8\nAdvanced und Predictive Analytics: Klassifikation\n\n\n9\nInformationsbereitstellung: Visualisierungstechniken"
  },
  {
    "objectID": "01_VL.html#quellen",
    "href": "01_VL.html#quellen",
    "title": "Business Intelligence & Data Science",
    "section": "Quellen",
    "text": "Quellen\n\n\nBusiness Intelligence & Data Science, SoSe 2024\n\n\n\nBaars, Henning, und Hans-Georg Kemper. 2021. Business Intelligence & Analytics: Grundlagen und praktische Anwendungen: Ansätze der IT-basierten Entscheidungsunterstützung. 4., überarbeitete und erweiterte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Vieweg.\n\n\nGesellschaft für Informatik. 2019. „Data Science: Lern- und Ausbildungsinhalte“. Gesellschaft für Informatik.\n\n\nSchieder, Christian. 2016. „Historische Fragmente einer Integrationsdisziplin – Beitrag zur Konstruktgeschichte der Business Intelligence“. In Analytische Informationssysteme, herausgegeben von Peter Gluchowski und Peter Chamoni, 13–32. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-47763-2_2.\n\n\nSharma, Vinod, Jeanne Poulose, und Chandan Maheshkar. 2023. „Analytics Enabled Decision Making ‚Tracing the Journey from Data to Decisions‘“. In Analytics Enabled Decision Making, herausgegeben von Vinod Sharma, Chandan Maheshkar, und Jeanne Poulose, 1–22. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-19-9658-0_1.\n\n\nWinter, Robert. 2016. „Analytische Informationssysteme aus Managementsicht: lokale Entscheidungsunterstützung vs. unternehmensweite Informations-Infrastruktur“. In Analytische Informationssysteme, herausgegeben von Peter Gluchowski und Peter Chamoni, 67–95. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-47763-2_5."
  },
  {
    "objectID": "02_VL_D.html#der-plan-für-heute",
    "href": "02_VL_D.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung 2\n\nDatenbereitstellung:\n\nData Warehouse\nData Mart\nArchitekturkonzepte\n\nBusiness Case: Der Musikstreaming Anbieter Tofispy braucht unsere Hilfe\nVerknüpfung eines ersten Data Marts mit Superset"
  },
  {
    "objectID": "02_VL_D.html#überblick-zum-bia-gesamteinsatz",
    "href": "02_VL_D.html#überblick-zum-bia-gesamteinsatz",
    "title": "Business Intelligence & Data Science",
    "section": "Überblick zum BIA Gesamteinsatz",
    "text": "Überblick zum BIA Gesamteinsatz\nDatenbereitstellung\n\n\n\nBIA Gesamtansatz. Eigene Darstellung in Anlehnung an Baars und Kemper (2021)."
  },
  {
    "objectID": "02_VL_D.html#data-warehouse",
    "href": "02_VL_D.html#data-warehouse",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nBegriff\n\n\n\n\n\n\nDefinition\n\n\nEin Data Warehouse (DWH) ist ein Datenhaltungssystem dispositiver Daten, das von den operativen Datenbeständen getrennt, themenorientiert aufbereitet und logisch zentralisiert ist. Ein DWH integriert unternehmensweit Datenbestände aus verschiedenen operativen internen Systemen (z.B. Kernbanksystemen und Enterprise-Ressource-Planning-Systemen) sowie externen Systemen (z.B. Börseninformationssystemen und Systeme für externe Ratings) und dient idealtypisch als unternehmensweite, einheitliche und konsistente Datenbasis für alle Arten von Systemen der Entscheidungsunterstützung (siehe Kemper und Sun 2023).\n\n\n\n\n\nDie entscheidenden Punkte sind hier:\n\nTrennung von operativen und dispositiven Daten\nIntegration von Datenbeständen aus verschiedenen und oftmals sehr heterogenen Quellen\nEinheitliche und konsistente Datenbasis für das gesamte Unternehmen"
  },
  {
    "objectID": "02_VL_D.html#data-warehouse-1",
    "href": "02_VL_D.html#data-warehouse-1",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nEigenschaften\n\n\n\nThemenorientierung:\n\nDispositive Daten des DWH sind explizit an den Interessenslagen der Entscheidenden ausgerichtet\nDie operativen bzw. externen Daten werden vor der Speicherung im DWH aufbereitet, harmonisiert und ggf. voraggregiert\nThemen sind Produkthierarchien, vordefinierte Zeiträume wie Quartale oder betriebswirtschaftliche Kennzahlen wie DB1\n\nIntegration:\n\nDaten aus den unterschiedlichen operativen und externen Systemen werden im DWH integriert\nZusammenführung zu einer inhaltlich widerspruchfreien Datenquelle, sogenannter “single point of truth”"
  },
  {
    "objectID": "02_VL_D.html#data-warehouse-2",
    "href": "02_VL_D.html#data-warehouse-2",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nEigenschaften\n\n\nZeitraumbezug:\n\nOperative Systeme sind transaktionsorientiert und bilden einen bestimmten Zeitpunkt ab\nDaten im DWH werden üblicherweise auf Zeiträume aggregiert, bspw. ein Monat oder ein Jahr\n\nNicht-Volatilität:\n\nDaten im DWH werden dauerhaft abgelegt und für die Analyse zur Verfügung gestellt\nDWH-Daten werden somit in der Regel nicht mehr geändert, überschrieben oder entfernt"
  },
  {
    "objectID": "02_VL_D.html#data-warehouse-3",
    "href": "02_VL_D.html#data-warehouse-3",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nKomponenten des Data Warehouse\n\n\n\nData Mart\n\nSeparater Datenpool für einen bestimmten Anwendungsbereich spezifischer Abteilungen\nNur ein Ausschnitt aus dem gesamten Datenpool, häufig aus Performance-Erwägungen\nHäufig mit Reporting- und OLAP assoziiert, zunehmend aber auch für Analysen\n\n\nCore Data Warehouse\n\nRückrat der meisten Architekturkonzepte und oft als Basisdatenbank bezeichnet\nBefüllung über ETL-Prozesse aus operativen Quellsystemen\nMeist auf relationalen Datenhaltungssystemen basierend mit großen Datenvolumina (TB Bereich)\nApplikationsneutral modelliert"
  },
  {
    "objectID": "02_VL_D.html#data-warehouse-4",
    "href": "02_VL_D.html#data-warehouse-4",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nFunktionen des CDWH\n\nSammel- und Integrationsfunktion:\n\n\n\nAufnahme aller wichtigen Daten für die Analyse in Form eines zentralen Datenlagers\n\n\n\nDistributionsfunktion:\n\n\n\nVersorgung aller nachgeschalteten Data Marts mit Daten\n\n\n\nQualitätssicherungsfunktion:\n\n\n\nDatentransformation sichert die syntaktische und semantische Stimmigkeit der dispositiven Datenbasis"
  },
  {
    "objectID": "02_VL_D.html#data-warehouse-5",
    "href": "02_VL_D.html#data-warehouse-5",
    "title": "Business Intelligence & Data Science",
    "section": "Data Warehouse",
    "text": "Data Warehouse\nData Mart vs. CDWH\n\n\n\nCharakteristika von Data Mart und Core Data Warehouse im Vergleich. In Anlehnung an Baars und Kemper (2021)\n\n\n\n\n\n\n\n\nData Mart\nCore Data Warehouse\n\n\n\n\nZiel\nEntscheidungsunterstützung für ausgewählte Bereiche, spezifisch auf Analyseanforderungen zugeschnitten\nEntscheidungsunterstützung für alle Bereiche in einem Unternehmen\n\n\nAusrichtung\nBereichsspezifisch oder Abteilungsbezogen\nZentral und unternehmensweit\n\n\nGranularität\nHöhere Aggregationen\nFeinste verfügbare Granularität\n\n\nVerfügbarkeit für Endanwendende\nIn der Regel möglich\nHäufig nicht erlaubt da zentral durch IT betrieben und als Quellsystem für Marts genutzt\n\n\nFlexibilität der Analysen\nTendenziell gering und auf Anwendungsbereich beschränkt\nSehr flexibel\n\n\nVolumina\nGering bis moderat\nModerat bis umfangreich"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen",
    "href": "02_VL_D.html#dwh-architekturen",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nUnabhängige Data Marts\n\n\n\n\n\n\n\n\nUnabhängige Data Marts. Eigene Darstellung in Anlehnung an Hahne (2016)\n\n\n\n\n\n\nAuch Stove-Pipe Ansatz\nBedienen sich direkt aus den operativen und externen Systemen\nBereiten die enthaltenen Daten für relevante Anwendungsfelder auf\nDaten werden isoliert bezogen und fließen direkt in Datensilos auf Basis bereichsspezifischer Fragestellungen\nVerschiedene Marts können unterschiedliche externe Datenquellen zusammenführen\n\n\n\n\n\n\nStove-Pipe Ansatz heißt so viel wie Ofenrohr, also eine direkte Verbindung zwischen Quelle und Ziel"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-1",
    "href": "02_VL_D.html#dwh-architekturen-1",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nUnabhängige Data Marts\n\n\n\nVorteile:\n\nSchnelle und bereichsspezifische Informationsbereitstellung\nSinnvoll bei fehlender Governance Strategie\nErfüllung maßgeschneideter bereichsspezifischer Fragestellungen\n\n\nNachteile:\n\nHäufig historisch gewachsene Strukturen und damit geringe Governance\nMehrfache Aufbereitung der Quelldaten\nGefahr von Inkonsistenzen bei der Kennzahlenberechnung zwischen Marts\nMangelnde Möglichkeit bereichsübergreifender Analysen"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-2",
    "href": "02_VL_D.html#dwh-architekturen-2",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nAbgestimmte Data Marts\n\n\n\n\n\n\n\nAbhängige Data Marts. Eigene Darstellung in Anlehnung an Hahne (2016)\n\n\n\n\n\n\nKonzeptionell abgestimmte Datenmodelle um die Integrität des Datenmaterials zu gewährleisten\nDas abgestimmte Datenmodell dient der syntaktischen und semantischen Vereinheitlichung\nInhaltliche und zeitliche Übereinstimmung der Datenextraktionen ist entscheidend für die Konsistenz der Data Marts"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-3",
    "href": "02_VL_D.html#dwh-architekturen-3",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nAbgestimmte Data Marts\n\n\n\nVorteile:\n\nIntegrität des Datenmodells wird gewährleistet\nMöglichkeit bereichsübergreifender Analysen bei hoher Flexibilität innerhalb der Bereiche\nEntscheidungsunterstützung für alle Bereiche in einem Unternehmen\n\n\nNachteile:\n\nDurch hohen Bereichsbezug oft unterschiedliche Granularität oder Aufbereitung, damit nur bedingte Integration zwischen Marts\nMöglicherweise höherer Abstimmungsbedarf zwischen Abteilungen bei der Kennzahldefinition\nInformationsverlust bei übergreifenden Analysen"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-4",
    "href": "02_VL_D.html#dwh-architekturen-4",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse\n\n\n\n\n\n\n\nCore Data Warehouse. Eigene Darstellung in Anlehnung an Hahne (2016)\n\n\n\n\n\n\nDas CDWH wird direkt aus den operativen Quellsystemen befüllt und basiert auf einer relationalen Datenbank\nDieser Ansatz wird oft als Monolith bezeichnet\nDie Daten decken unterschiedliche Auswertungszwecke ab und sind weniger anwendungsbezogen als Datensilos"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-5",
    "href": "02_VL_D.html#dwh-architekturen-5",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse\n\n\n\nVorteile:\n\nHoher Grad an Mehrfachverwendbarkeit der Daten\nHoher Detailgrad möglich\nBei kleineren Anwendungsfällen oft ausreichend\n\n\nNachteile:\n\nBerechtigungsmanagement und Performance stoßen bei komplexen Anwendungsfällen schnell an Grenzen\nBei größeren Einheiten mit eigenen Geschäftsprozessen und stark abweichenden Hierarchiestrukturen sehr komplex, hier bietet sich der Einsatz mehrerer CDWH an"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-6",
    "href": "02_VL_D.html#dwh-architekturen-6",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse mit abhängigen Data Marts\n\n\n\n\nAuch Hub-and-Spoke Ansatz genannt\nCDWH wird nicht direkt für Analysen herangezogen, sondern dient der Befüllung von Marts\nMarts sind dann anwendungsbezogen, weisen aber ein einheitliches Datenmodell auf\nCDWH als Hub erfüllt Aufgaben der Integration, Qualitätssicherung und Datenverteilung an die Marts\n\n\n\n\n\n\n\n\nCore Data Warehouse mit abhängigen Data Marts. Eigene Darstellung in Anlehnung an Hahne (2016)"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-7",
    "href": "02_VL_D.html#dwh-architekturen-7",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nCore Data Warehouse mit abhängigen Data Marts\n\n\n\nVorteile:\n\nEinmaliger und einheitlicher Transformationsprozess ohne redundante Transformationslogik\nGeringere Anzahl an Extraktionsprozessen\nReduzierte Anzahl direkter Schnittstellen zwischen Marts und operativen Daten\n\n\nNachteile:\n\nNach wie vor eher traditionelle BI-Sicht"
  },
  {
    "objectID": "02_VL_D.html#dwh-architekturen-8",
    "href": "02_VL_D.html#dwh-architekturen-8",
    "title": "Business Intelligence & Data Science",
    "section": "DWH Architekturen",
    "text": "DWH Architekturen\nArchitekturen-Mix\n\n\n\n\n\nArchitekturen-Mix. Eigene Darstellung in Anlehnung an Hahne (2016)"
  },
  {
    "objectID": "02_VL_D.html#business-case",
    "href": "02_VL_D.html#business-case",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nDas Wachstum bei Tofispy stagniert\n\n\n\nTofispy ist ein Musikstreaming Anbieter aus Deutschland\nDas Unternehmen kämpft mit stagnierendem Wachstum\nWir – die Unternehmensberatung LeinbizConsult – wurden beauftragt, die Gründe für das stagnierende Wachstum zu identifizieren und Handlungsempfehlungen zu entwickeln\nDie Geschäftsführung hat uns erste Daten zur Verfügung gestellt, um die aktuelle Situation zu evaluieren und Ursachenforschung zu betreiben"
  },
  {
    "objectID": "02_VL_D.html#business-case-1",
    "href": "02_VL_D.html#business-case-1",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nDatensatz\n\nÜberblick über den Streamingmarkt:\n\nTabelle “market_share” im Dataset Market Research\nAnzahl der Nutzer pro Plattform in Mio\nDaten von 2016 bis 2024\nDie Daten für 2024 sind eine Hochrechnung für das laufende Jahr"
  },
  {
    "objectID": "02_VL_D.html#business-case-2",
    "href": "02_VL_D.html#business-case-2",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nAufgabe\n\n\nArbeit in 2er Teams mit mindestens einem Laptop oder Tablet pro Team, Laptop ideal\nTrial & Error in Superset mit Hilfe der Dokumentation:\n\nDokumentation unter preset.io\nStartpunkt: Creating a Chart (in der preset Doku)\nTable oder Preview im SQL Editor als Ausgangspunkt für explorative Analyse\n\nZiel:\n\nGestapeltes Balkendiagramm für die relativen Marktanteile der Plattformen im Zeitverlauf\nLiniendiagramm für die absolute Marktentwicklung"
  },
  {
    "objectID": "02_VL_D.html#business-case-3",
    "href": "02_VL_D.html#business-case-3",
    "title": "Business Intelligence & Data Science",
    "section": "Business Case",
    "text": "Business Case\nFragen (ggf. als Hausaufgabe)\n\n\nWächst Tofispy schneller oder langsamer als der Gesamtmarkt?\nWie hoch ist der Marktanteil am Ende von 2024 voraussichtlich?\nWelcher Konkurrent wächst am stärksten?\nIst der Datensatz operativ oder dispositiv?\nWelcher Reifegrad von Analytics liegt vor?"
  },
  {
    "objectID": "02_VL_D.html#quellen",
    "href": "02_VL_D.html#quellen",
    "title": "Business Intelligence & Data Science",
    "section": "Quellen",
    "text": "Quellen\n\n\nBusiness Intelligence & Data Science, SoSe 2024\n\n\n\nBaars, Henning, und Hans-Georg Kemper. 2021. Business Intelligence & Analytics: Grundlagen und praktische Anwendungen: Ansätze der IT-basierten Entscheidungsunterstützung. 4., überarbeitete und erweiterte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Vieweg.\n\n\nHahne, Michael. 2016. „Architekturkonzepte und Modellierungsverfahren für BI-Systeme“. In Analytische Informationssysteme, herausgegeben von Peter Gluchowski und Peter Chamoni, 147–85. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-47763-2_8.\n\n\nKemper, Hans-Georg, und Xuanpu Sun. 2023. „Data Warehouse“. In Gabler Bankenlexikon. https://www.gabler-banklexikon.de/definition/data-warehouse-56847/version-377924."
  },
  {
    "objectID": "04_VL.html#der-plan-für-heute",
    "href": "04_VL.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung 4\n\nBig Data:\n\nWas ist Big Data?\nDefinitionen und Eigenschaften\nTechnologien und Werkzeuge\nAnwendungsfälle\n\nData Lake:\n\nWas ist der Data Lake?\nBraucht man das?\nWas sind die Unterschiede zum Data Warehouse?"
  },
  {
    "objectID": "04_VL.html#einordnung-in-den-gesamtkontext",
    "href": "04_VL.html#einordnung-in-den-gesamtkontext",
    "title": "Business Intelligence & Data Science",
    "section": "Einordnung in den Gesamtkontext",
    "text": "Einordnung in den Gesamtkontext\nDer Data Lake & Big Data\n\n\n\nBIA Gesamtansatz. Eigene Darstellung in Anlehnung an Baars und Kemper (2021)."
  },
  {
    "objectID": "04_VL.html#big-data-1",
    "href": "04_VL.html#big-data-1",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\nWas ist Big Data?\n\n\n\nQuelle: Siemens Stiftung 2019"
  },
  {
    "objectID": "04_VL.html#big-data-2",
    "href": "04_VL.html#big-data-2",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\nDie 3Vs\n\n\n\n\nVolume:\n\nDie erhebliche Menge an Daten, die erfasst oder generiert wird und die vorgehalten sowie gespeichert werden muss\nD’Onofrio und Meier (2021) sprechen im Petabyte bis Zettabyte-Bereich von Big Data\n\nVariety:\n\nMeint die unterschiedlichen Arten von Daten in Big Data-Szenarien\nNeben strukturierte Daten in Tabellenform auch um unstrukturierte Daten wie Texte, Bilder, Videos, Audios sowie semi-strukturierte Daten\n\nVelocity:\n\nDie Rate, mit der Daten erzeugt, gesammelt und verarbeitet werden.\nIm Extremfall müssen Daten in Echtzeit analysiert werden, um sofortige Erkenntnisse zu gewinnen.\n\n\n\n\n\n\n\nQuelle: Siemens Stiftung 2019"
  },
  {
    "objectID": "04_VL.html#big-data-3",
    "href": "04_VL.html#big-data-3",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\n…und noch mehr Vs\n\nWeitere Vs in der Literatur zielen auf die Verwendung der Daten ab und weniger auf die technischen Eigenschaften der 3 Vs\n\n\nValue (Wert)\n\nDer Wert, den Unternehmen aus den gesammelten und analysierten Daten ziehen können\nDas Hauptziel von Big Data ist es, nutzbare Erkenntnisse zu gewinnen und daraus einen Mehrwert zu generieren"
  },
  {
    "objectID": "04_VL.html#big-data-4",
    "href": "04_VL.html#big-data-4",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\n…und noch mehr Vs\n\nVeracity (Genauigkeit)\n\nDie Qualität der Daten, besonders Präzision und Zuverlässigkeit, da große Daten oft Rauschen und ungenaue Informationen enthalten\nBaars und Kemper (2021) betonen, dass Genauigkeit auf die durch Big Data erzielten Ergebnisse abzielt und weniger auf die Daten\n\nValidity (Validität)\n\nDie Gültigkeit der Datenanalyse, inwiefern die durchgeführten Analysen tatsächlich die gewünschten Erkenntnisse liefern\n\nOutput Velocity (Analyse-Geschwindigkeit)\n\nDie Bereitstellung von relevanten Ergebnissen mit geringer Latenz, idealerweise nahezu in Echtzeit"
  },
  {
    "objectID": "04_VL.html#big-data-5",
    "href": "04_VL.html#big-data-5",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\nTechnologien und Werkzeuge\n\nBig Data Technologien müssen hohe Datenvolumina im mehrstelligen Petabyte-Bereich handhaben, um hierauf Analysen durchzuführen\nDie Ergebnisse dieser Analysen gilt es hiernach im IT-Entscheidungsunterstützungssystem zu integrieren\nDies ist mit den bisher vorgestellten relationalen CDWH-Lösungen nicht ohne Weiteres möglich\nDie aus den 3 Vs resultierenden Anforderungen erfordern hohe Rechen- und Speicherkapazitäten, die oft durch parallele Infrastruktur realisiert werden."
  },
  {
    "objectID": "04_VL.html#big-data-6",
    "href": "04_VL.html#big-data-6",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\nTechnologien und Werkzeuge\n\nAllgemein werden zwei Formen der Parallelisierung unterschieden:\n\nVertikale Skalierung:\n\nAuch Scale Up genannt\nNutzung von leistungsstärkeren Rechnern\n\nHorizontale Skalierung:\n\nAuch Scale Out genannt\nNutzung von vielen günstigen Standard-Servern oder Cloud Infrastruktur bei modernen Cloud Hyper Scalern, um Lasten zu verteilen\n\n\nVertikale Skalierung stößt schnell an technische Grenzen, horizontale Skalierung meist an Budgetgrenzen"
  },
  {
    "objectID": "04_VL.html#big-data-7",
    "href": "04_VL.html#big-data-7",
    "title": "Business Intelligence & Data Science",
    "section": "Big Data",
    "text": "Big Data\nTechnologien und Werkzeuge\n\nVertikale Skalierung stößt schnell an technische Grenzen, horizontale Skalierung meist an Budgetgrenzen\nDie Datenhaltung in Big Data-Szenarien erfolgt in der Regel in NoSQL-Datenbanken (Not Only SQL)\nDies dient primär der Parallelisierung der Datenhaltung und -verarbeitung\nGleichzeitig ermöglichen diese Datenbanken die Speicherung von unstrukturierten Daten"
  },
  {
    "objectID": "04_VL.html#nosql-datenbanken",
    "href": "04_VL.html#nosql-datenbanken",
    "title": "Business Intelligence & Data Science",
    "section": "NoSQL Datenbanken",
    "text": "NoSQL Datenbanken\nKey-Value Stores\n\n\n\nDatenbanken, die paarweise einen (einmaligen) Schlüssel mit einem zugehörigen Wert ablegen\nDiese Werte können beliebige Datenstrukturen sein, wie z.B. Texte, Bilder, Videos, Audios, JSON-Objekte, XML-Dateien, etc.\nKey-Value Stores sind optimiert für schnelle Lese- und Schreibzugriffe auf Basis von Keys\n\n\n\n\n\nKey Value Store, Quelle: Data Engineering Wiki"
  },
  {
    "objectID": "04_VL.html#nosql-datenbanken-1",
    "href": "04_VL.html#nosql-datenbanken-1",
    "title": "Business Intelligence & Data Science",
    "section": "NoSQL Datenbanken",
    "text": "NoSQL Datenbanken\nDocument Stores\n\n\n\nEnthalten poly-strukturierte Dokumente beliebiger Länge, die auf Basis von Dokumenteninhalten recherchiert werden können.\nHäufig in Form von JSON oder XML Files abgelegt, da diese die Möglichkeit bieten, unstrukturierte Attribute zu hinterlegen und flexible Schemata zu definiere.\nDas Beispiel rechts entspricht dem JavaScript Object Notation JSON\n\n\n\n\n\nDocument Data Base, Quelle: Data Engineering Wiki"
  },
  {
    "objectID": "04_VL.html#nosql-datenbanken-2",
    "href": "04_VL.html#nosql-datenbanken-2",
    "title": "Business Intelligence & Data Science",
    "section": "NoSQL Datenbanken",
    "text": "NoSQL Datenbanken\nWide Column Stores und Graph-Databases\n\n\n\n\nWide Column Stores:\n\nDatenbanken, die Daten mit einer jeweils variablen (dynamischen) Anzahl von Spalten und Subspalten verwalten können\nEinzelne Zeilen können eine unterschiedlichen Anzahl von Spalten beinhalten, die darüber hinaus sehr groß sein kann\n\nGraph-Databases:\n\nSind auf Ablage, Verarbeitung und Suche von vernetzten Datenstrukturen ausgerichtet.\nBasieren auf graph-typischen Strukturen mit Knoten und Kanten (Nodes and Edges), mit jeweils eigenen Attributen (Properties)\n\n\n\n\n\n\n\nGraph Database, Quelle: Data Engineering Wiki"
  },
  {
    "objectID": "04_VL.html#data-lake-1",
    "href": "04_VL.html#data-lake-1",
    "title": "Business Intelligence & Data Science",
    "section": "Data Lake",
    "text": "Data Lake\nDas Konzept des Data Lake\n\nDas Data Warehouse galt lange Zeit als das zentrale Architekturkonzept für dispositive Reporting- und Analysezwecke\nBig Data Technologien haben den Data Lake in den Fokus gerückt, der meist als eine ergänzende Komponente zu DWH dient\nEin Data Lake erhebt den Anspruch, alle Quelldaten in roher Form als Rohdaten zu persistieren und zur Verfügung zu stellen\nBeim Data Lake steht der effiziente Umgang mit großen und polystrukturierten Datenmengen im Vordergrund, die es schnell zu verarbeiten gilt\nDies ermöglicht komplexe Analysen für neue Machine Learning Anwendungen, die verschiedene Datenquellen benötigen"
  },
  {
    "objectID": "04_VL.html#data-lake-vs.-data-warehouse",
    "href": "04_VL.html#data-lake-vs.-data-warehouse",
    "title": "Business Intelligence & Data Science",
    "section": "Data Lake vs. Data Warehouse",
    "text": "Data Lake vs. Data Warehouse\nIllustration\n\n\n\nData Lake versus Data Warehouse, Quelle: Twitter"
  },
  {
    "objectID": "04_VL.html#data-lake-vs.-data-warehouse-1",
    "href": "04_VL.html#data-lake-vs.-data-warehouse-1",
    "title": "Business Intelligence & Data Science",
    "section": "Data Lake vs. Data Warehouse",
    "text": "Data Lake vs. Data Warehouse\nCharakteristika\n\n\n\nTabelle 1: Wichtige Charakteristika von Data Lake und Data Warehouse im Vergleich. In Anlehnung an Dittmar und Schulz (2023), S. 159\n\n\n\n\n\n\nData Warehouse\nData Lake\n\n\n\n\nOptimiert für wiederholbare Prozesse\nOriginär eine Erweiterung der DWH Staging Area\n\n\nUnterstützt eine Vielzahl von unternehmensinternen Informationsbedarfen\nOptimiert Daten für Analystics-Lösungen\n\n\nFokus auf vergangenheitsbezogene Auswertungen\nFokus auf unbekannte explorative Datenanalyse und zukunftsorienterte Methoden\n\n\nSchema-on-Write mit harmonisiertem Datenmodell\nSchema-on-Read mit Echtzeit Rohdaten Bewirtschaftung"
  },
  {
    "objectID": "04_VL.html#data-lake-vs.-data-warehouse-2",
    "href": "04_VL.html#data-lake-vs.-data-warehouse-2",
    "title": "Business Intelligence & Data Science",
    "section": "Data Lake vs. Data Warehouse",
    "text": "Data Lake vs. Data Warehouse\nAnwendungsbereiche\n\n\n\nAnwendungsfälle Data Lake und Data Warehouse, Quelle: Twitter"
  },
  {
    "objectID": "04_VL.html#data-lake-2",
    "href": "04_VL.html#data-lake-2",
    "title": "Business Intelligence & Data Science",
    "section": "Data Lake",
    "text": "Data Lake\nArchitekturprinzipien\n\n\nDatenanbindung:\n\nEs werden ausschließlich primäre Datenquellen angebunden\nDie feinste Granularität der Datenquelle wird verwendet\n\nDatenhaltung\n\nEine Löschung der Rohdaten erfolgt nur aus regulatorischen Gründen (Datenschutz)\nEin Zonenkonzept ist zu empfehlen\nEine Anonymisierung persönlicher Daten erfolgt während der Beladung\n\nDatenplattform\n\nInfrastructure as Code wird angestrebt\nEine Portierbarkeit zur Vermeidung von Vendor-Lock-In wird angestrebt\nEin zentrales Identity Management System steuert Zugriffe granular\nEin Datenkatalog mit fachlicher und operativer Perspektive wird empfohlen"
  },
  {
    "objectID": "04_VL.html#data-lake-3",
    "href": "04_VL.html#data-lake-3",
    "title": "Business Intelligence & Data Science",
    "section": "Data Lake",
    "text": "Data Lake\nZonen\n\nÄhnlich wie im ETL Prozess umfasst auch der Data Lake verschiedene Zonen, in denen die Daten verschiedene Prozesse durchlaufen:\n\n\n\nTransient Zone: Eingangsbereich, in den alle Daten in Rohform extrahiert werden, Daten werden nicht dauerhaft vorgehalten und es wird ggf. anonymisiert\nRaw Data Zone: Alle Daten werden in ihrer möglichst rohen Form dauerhaft vorgehalten\nCurated Zone: Hier werden aufbereitete Daten hinterlegt, die bereits Filterprozesse durchlaufen haen und von Mängeln befreit wurden\nDiscovery Sandbox: Hier werden Daten für direkten Zugriff durch Analysten bereitgestellt\nConsumption Zone: Hier stehen vollständig transformierte, angereicherte und aggregierte Daten für die Endnutzung zur Verfügung"
  },
  {
    "objectID": "04_VL.html#quellen",
    "href": "04_VL.html#quellen",
    "title": "Business Intelligence & Data Science",
    "section": "Quellen",
    "text": "Quellen\n\n\nBusiness Intelligence & Data Science, SoSe 2024\n\n\n\nBaars, Henning, und Hans-Georg Kemper. 2021. Business Intelligence & Analytics: Grundlagen und praktische Anwendungen: Ansätze der IT-basierten Entscheidungsunterstützung. 4., überarbeitete und erweiterte Auflage. Lehrbuch. Wiesbaden [Heidelberg]: Springer Vieweg.\n\n\nD’Onofrio, Sara, und Andreas Meier, Hrsg. 2021. Big Data Analytics: Grundlagen, Fallbeispiele und Nutzungspotenziale. Edition HMD. Wiesbaden: Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-32236-6.\n\n\nDittmar, Carsten, und Peter Schulz. 2023. „Architekturen und Technologien für den Data Lake“. In Künstliche Intelligenz und Data Science in Theorie und Praxis, herausgegeben von Andreas Gillhuber, Göran Kauermann, und Wolfgang Hauner, 157–66. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-66278-6_12.\n\n\nQuix, Christoph. 2021. „Big-Data-Technologien“. In Data Science, herausgegeben von Detlev Frick, Andreas Gadatsch, Jens Kaufmann, Birgit Lankes, Christoph Quix, Andreas Schmidt, und Uwe Schmitz, 133–48. Wiesbaden: Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-33403-1_8."
  },
  {
    "objectID": "99_VL.html#der-plan-für-heute",
    "href": "99_VL.html#der-plan-für-heute",
    "title": "Business Intelligence & Data Science",
    "section": "Der Plan für heute…",
    "text": "Der Plan für heute…\nVorlesung\n\n\nBusiness Intelligence & Data Science, SoSe 2024"
  }
]